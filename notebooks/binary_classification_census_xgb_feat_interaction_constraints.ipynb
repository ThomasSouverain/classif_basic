{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Basic data preparation, modelling and analysis for binary classification (Census)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03693",
   "metadata": {},
   "source": [
    "## Train a model only with a statistical performance purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from classif_basic.data_preparation import train_valid_test_split, set_target_if_feature, automatic_preprocessing\n",
    "from classif_basic.model import train_naive_xgb, pickle_save_model, prediction_train_valid_by_task, compute_best_fscore\n",
    "from classif_basic.model_analysis import features_importances_from_pickle, augment_train_valid_set_with_results\n",
    "\n",
    "from classif_basic.model_analysis import plot_tree, get_df_first_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107aa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your statistics purposes\n",
    "model_task = 'classification'\n",
    "stat_criteria = 'auc'\n",
    "\n",
    "preprocessing_cat_features = 'label_encoding'\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124240e",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "Fix precise % of population distribution (sex: Male, Female) and % of loan granted according to sex, to inspect the effects of FairDream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a741869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset on clients for binary classification\n",
    "#from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target == '>50K') * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = X.copy()\n",
    "dataset['target'] = Y\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, \"treatment\" is saw as being 'Male' and not 'Female'\n",
    "\n",
    "df_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==1)]\n",
    "df_no_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==0)]\n",
    "df_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==1)]\n",
    "df_no_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==0)]\n",
    "\n",
    "print(df_response_if_feature.shape[0])\n",
    "print(df_no_response_if_feature.shape[0])\n",
    "print(df_response_if_not_feature.shape[0])\n",
    "print(df_no_response_if_not_feature.shape[0])\n",
    "\n",
    "\n",
    "# % of men selected by the initial data\n",
    "df_response_if_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of women selected by the initial data\n",
    "df_response_if_not_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_not_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dataset = 20_000\n",
    "\n",
    "percentage_feature= 70\n",
    "percentage_response_if_feature=70\n",
    "percentage_response_if_not_feature=10\n",
    "\n",
    "sexist_dataset = set_target_if_feature(\n",
    "    df_response_if_feature=df_response_if_feature,\n",
    "    df_no_response_if_feature=df_no_response_if_feature,\n",
    "    df_response_if_not_feature=df_response_if_not_feature,\n",
    "    df_no_response_if_not_feature=df_no_response_if_not_feature,\n",
    "    len_dataset=len_dataset,\n",
    "    percentage_feature=percentage_feature,\n",
    "    percentage_response_if_feature=percentage_response_if_feature,\n",
    "    percentage_response_if_not_feature=percentage_response_if_not_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sexist_dataset.loc[: , dataset.columns != 'target']\n",
    "Y = sexist_dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb9644",
   "metadata": {},
   "source": [
    "### Bring your own model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a8be6",
   "metadata": {},
   "source": [
    "If you want to bring your own model, you have to set 3 features:\n",
    "\n",
    "1. uncorrected_model_path\n",
    "Save your model in uncorrected_model_path, for fairness analysis on relevant features\n",
    "Ex: uncorrected_model_path = \"/work/data/models/uncorrected_model.pkl\"\n",
    "\n",
    "2. X_train_valid, Y_train_valid\n",
    "pd.DataFrame with your inputs and targets on train&valid set, of shape(nb_individuals,)\n",
    "\n",
    "3. Y_pred_train_valid\n",
    "np.ndarray with the predicted label (i.e. class) or value, of shape(nb_individuals,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447f8c",
   "metadata": {},
   "source": [
    "### Automatically train a model statistically performant, regardless of fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf564bb",
   "metadata": {},
   "source": [
    "We here introduce additional interaction constraints, to reflect causal interpretation on the features (TODO later: option of the function \"train_naive_xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e01c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_train_valid, X_test, Y_train, Y_valid, Y_train_valid, Y_test = train_valid_test_split(\n",
    "    X=X,\n",
    "    Y=Y, \n",
    "    model_task=model_task,\n",
    "    preprocessing_cat_features=preprocessing_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e26fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438539df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save the uncorrected model, to then sort its features by importances\n",
    "save_model=True\n",
    "uncorrected_model_path = \"/work/data/models/uncorrected_model.pkl\"\n",
    "\n",
    "Y_pred_train_valid = train_naive_xgb(\n",
    "    X_train=X_train,\n",
    "    X_valid=X_valid,\n",
    "    X_train_valid=X_train_valid,\n",
    "    X_test=X_test,\n",
    "    Y_train=Y_train,\n",
    "    Y_valid=Y_valid,\n",
    "    Y_train_valid=Y_train_valid,\n",
    "    Y_test=Y_test,\n",
    "    model_task=model_task,\n",
    "    stat_criteria=stat_criteria,\n",
    "    save_model=save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e5fb6",
   "metadata": {},
   "source": [
    "We now see that this process with basic data preparation, modelling and integration of the results in a DataFrame (as storage of the model) is very fast (in seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "print(f\"Basic modelling took {round(t1 - t0)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8000cb",
   "metadata": {},
   "source": [
    "# Decomposition in Trees: Coherent Structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54466f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(uncorrected_model_path,'rb')\n",
    "xgb_basic = pickle.load(file)\n",
    "\n",
    "xgb_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed016f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "booster = xgb_basic\n",
    "get_max_split_feature=False\n",
    "nb_min_trees = 4 #None\n",
    "\n",
    "df_first_splits = get_df_first_splits(booster=booster, \n",
    "                                      get_max_split_feature=get_max_split_feature,\n",
    "                                      nb_min_trees=nb_min_trees)\n",
    "df_first_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e8bfa",
   "metadata": {},
   "source": [
    "With feature interaction constraints on sex being not uncoherent ancestor of 'age', 'race' or 'native-country' the splitting of trees seem more coherent. \n",
    "\n",
    "TODO: now, how to set other causal parenthoods (e.g. 'relationship' can not be a causal ancestor of 'education', I think?) May be some links have to be sacrified, in order to draw efficient splits..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c541981",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "first_splitting_feature = df_first_splits.index[0]\n",
    "\n",
    "print(f\"first_splitting_feature: {first_splitting_feature}\")\n",
    "\n",
    "for num_trees in df_first_splits[\"trees_index\"][first_splitting_feature]:\n",
    "    \n",
    "    plot_tree(\n",
    "        booster=xgb_basic,\n",
    "        num_trees=num_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8b11f",
   "metadata": {},
   "source": [
    "Parallell with the feature importance: aggregation over trees, but no \"sense\" or hierarchy between features... \n",
    "\n",
    "#Conclusion#\n",
    "- The features importances does not reflect the structures of the trees\n",
    "- The structures of the trees do not (systematically) follow a causal hierarchy (e.g. splitting on the income before the age) \n",
    "=> Further tests: the structures of trees need to be causally constrained (even if the split on \"capital_gain\" before \"education_num\" on a tree brought a bigger node purity on a tree number_k, that order would be forbidden as unrealistic)\n",
    "\n",
    "Intuition: only keep the leaves that make sense \n",
    "\n",
    "Incident questions to realise this selection, or constraint, on trees: \n",
    "n_estimators = 1000, then why n_trees = 109?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d8665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost.plotting import plot_importance \n",
    "\n",
    "# importance_type : str, default \"weight\"\n",
    "        #How the importance is calculated: either \"weight\", \"gain\", or \"cover\"\n",
    "        #* \"weight\" is the number of times a feature appears in a tree\n",
    "        \n",
    "plot_importance(\n",
    "    booster=xgb_basic,\n",
    "    importance_type=\"weight\",\n",
    "    max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#* \"gain\" is the average gain of splits which use the feature\n",
    "plot_importance(\n",
    "    booster=xgb_basic,\n",
    "    importance_type=\"gain\",\n",
    "    max_num_features=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
