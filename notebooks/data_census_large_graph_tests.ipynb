{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2affb517",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "In this notebook, we inspect **in which way a tabular dataset as Census can be used by an AI based on graphs to estimate wealthiness of individuals**. \n",
    "\n",
    "Therefore, we proceed in 2 steps:\n",
    "\n",
    "**1. We prepare data to be handled by a model based on a graph**\n",
    "We transform them into a graph, that involves strong assumptions on the features involved in connections...\n",
    "\n",
    "**2. We train an AI based on graphs**\n",
    "Here, we begin with a Graphical Neural Network (GNN) based on a Multi-Layer Perceptron (MLP), requiring the library Torch.\n",
    "\n",
    "**3. We inspect if the graph-based AI indeed reflects common & expert knowledge on**\n",
    "In particular, regarding the non-sense of certain inferences that should absolutely be avoided (e.g. education may influence occupation, but not the reverse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Data preparation for binary classification with graphs (Census)\n",
    "For this reshaping (and also interpretation, see below the choice of edges) of data tables to graphs, we used a basic Google [colab](https://colab.research.google.com/drive/1_eR7DXBF3V4EwH946dDPOxeclDBeKNMD?usp=sharing#scrollTo=WuggdIItffpv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03693",
   "metadata": {},
   "source": [
    "## General preparation - handle categorical features\n",
    "Here, we handle the categorical features through label-encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676925f",
   "metadata": {},
   "source": [
    "As we need to install torch-scatter and torch-sparse to enable torch_geometric (enabling our transformation of data in table, and the GNN), which seem not compatible with GPU on poetry, we use a [trick](https://stackoverflow.com/questions/74823704/error-building-wheel-for-torch-sparse-error-installing-pytorch-geometric) to install them on notebook with pip (to be cleaned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771274e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "try:\n",
    "    import torch_geometric\n",
    "except ModuleNotFoundError:\n",
    "    TORCH = torch.__version__.split(\"+\")[0]\n",
    "    CUDA = \"cu\" + torch.version.cuda.replace(\".\",\"\")\n",
    "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "#!pip install torch-geometric\n",
    "#import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import time\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from classif_basic.data_preparation import handle_cat_features, train_valid_test_split\n",
    "\n",
    "from classif_basic.graph import table_to_graph, add_new_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124240e",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a741869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset on clients for binary classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target == '>50K') * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7180da",
   "metadata": {},
   "source": [
    "### Add pre-processing: split hours-per-week in 2 quantiles, to use it as an edge (combined with \"occupation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7347572",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"hours-per-week\"].value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52305d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hours = X[\"hours-per-week\"].median() # '1' if the client works over 40 hours per week\n",
    "\n",
    "X[\"hours-per-week\"] = (X[\"hours-per-week\"] == median_hours).astype(int)\n",
    "X[\"hours-per-week\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99abfa",
   "metadata": {},
   "source": [
    "## Reshape (by interpreting) data to a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756db59",
   "metadata": {},
   "source": [
    "From this dataset (where we introduced selectively a \"sexist\" effect against women), let's see how we could swith from the tabular data to a graph representation.\n",
    "\n",
    "The point is that our features X all seem to be attributes of the clients, though we should find a way of representing their interactions between clients \n",
    "\n",
    "X = {race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, occupation, hours per week, workclass, race, sex, capital gain, capital loss, native country} \n",
    "\n",
    "**Nodes** \n",
    "Bank clients (by ID)\n",
    "\n",
    "**Edges** \n",
    "Here, we should find one or several ways of connecting the clients\n",
    "\n",
    "Should be occupation → if changes of occupation (or similar client with new occupation), which impact on the revenue? // change of football team => impact on the football rate \n",
    "(pers) actionable => predict revenue when switches to a new job??\n",
    "→ may be: “hours per week” <=> inspect the change of revenue if switches to greater hours per week?\n",
    "\n",
    "**Node Features** \n",
    "Attributs of the nodes, i.e. characteristics of the clients (here, hard to separate from what \"connects\" them...) \n",
    "\n",
    "Race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, hours per week, workclass, race, sex, capital gain, capital loss, native country \n",
    "\n",
    "**Label (here at a node-level?)** \n",
    "Income (Y = income > $50 000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f6878e",
   "metadata": {},
   "source": [
    "Test of my idea: create graphs with different edges, here sex (graph 1) -> education (graph 2)?\n",
    "\n",
    "Or enforce causal hierarchy through the neighborhood definition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faf0c92",
   "metadata": {},
   "source": [
    "As it is in use in the creation of batches by neighbors with PyTorch Geometric, we split the data inside the function and keep their train/valid/test masks (i.e. boolean tensor indicating if the individual is in X_train/X_valid/X_test).\n",
    "\n",
    "As for instance, data_total.train_mask will be required to pass in \"input_nodes\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba30f2",
   "metadata": {},
   "source": [
    "## Split between data used for GNN training / test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 7\n",
    "VALID_SIZE = 0.15\n",
    "preprocessing_cat_features = \"label_encoding\"\n",
    "\n",
    "X = handle_cat_features(X=X, preprocessing_cat_features=preprocessing_cat_features)\n",
    "\n",
    "# Split valid set for early stopping & model selection\n",
    "# \"stratify=Y\" to keep the same proportion of target classes in train/valid (i.e. model) and test sets \n",
    "X_model, X_test, Y_model, Y_test = train_test_split(\n",
    "    X, Y, test_size=VALID_SIZE, random_state=SEED, stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e527d61",
   "metadata": {},
   "source": [
    "## Transformation of model / test data into graphs with the same attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2960cf",
   "metadata": {},
   "source": [
    "First, shape the data used for GNN training in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabcd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute edge by hands: create our own edge combination, to predict the income - with directed paths\n",
    "# first edge joins \"occupation\" -> \"hours-per-week\"\n",
    "# second edge joins \"sex\" -> \"education\"\n",
    "X_total = X_model\n",
    "Y_total = Y_model\n",
    "\n",
    "list_col_names=[\"occupation\", \"hours-per-week\"] # test the model with only 2 categories (> or < median of work hours)\n",
    "\n",
    "edges_total = add_new_edge(data=X_total, previous_edge=None, list_col_names=[\"occupation\", \"hours-per-week\"])\n",
    "#edges_total = add_new_edge(data=X_total, previous_edge=edges_total, list_col_names=[\"sex\",\"education\"]\n",
    "\n",
    "# for training by specifying \"masks\" (i.e. boolean for nodes = individuals selected to train the GNN), \n",
    "# add a specification on train indexes \n",
    "data_total = table_to_graph(X=X_total, Y=Y_total, list_col_names=list_col_names, edges=edges_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a07489",
   "metadata": {},
   "source": [
    "Do exactly the same for test data (will be used for GNN test evaluation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_names=[\"occupation\", \"hours-per-week\"] # test the model with only 2 categories (> or < median of work hours)\n",
    "\n",
    "edges_test = add_new_edge(data=X_test, previous_edge=None, list_col_names=[\"occupation\", \"hours-per-week\"])\n",
    "#edges_test = add_new_edge(data=X_test, previous_edge=edges_test, list_col_names=[\"sex\",\"education\"]\n",
    "\n",
    "# for training by specifying \"masks\" (i.e. boolean for nodes = individuals selected to train the GNN), \n",
    "# add a specification on train indexes \n",
    "data_test = table_to_graph(X=X_test, Y=Y_test, list_col_names=list_col_names, edges=edges_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b5cd3",
   "metadata": {},
   "source": [
    "# Train a basic Graph Neural Network on the graph-shaped data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cde5a",
   "metadata": {},
   "source": [
    "## Train with batches (neighborhood sampling) a basic GCN \n",
    "\n",
    "Here, we try using the batches constituted from neighborhoods to train the GNN, using our GPU (if accessed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d146d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classif_basic.graph import train_GNN\n",
    "\n",
    "gnn_basic = train_GNN(\n",
    "                data_total=data_total,\n",
    "                loader_method=\"neighbor_nodes\",\n",
    "                batch_size = 32,\n",
    "                epoch_nb = 2,\n",
    "                learning_rate = 0.01,\n",
    "                nb_neighbors_per_sample = 30,\n",
    "                nb_iterations_per_neighbors = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32385c",
   "metadata": {},
   "source": [
    "## Inspect the predictions of the model on valid and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b56e7a",
   "metadata": {},
   "source": [
    "Let's inspect the model on test data, to assess if the stability of performance is not due to coincidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109cc85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from classif_basic.graph import evaluate_gnn\n",
    "\n",
    "classifier=gnn_basic\n",
    "data_test=data_test\n",
    "loss_name=\"cross_entropy\"\n",
    "\n",
    "# unfortunately, memory error... Evaluate per batches? Or create an independant data_test? // Evaluate on valid \n",
    "\n",
    "evaluate_gnn(\n",
    "    classifier=gnn_basic, \n",
    "    data_test=data_test, \n",
    "    loss_name=loss_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f7e6a",
   "metadata": {},
   "source": [
    "**No Overfitting**\n",
    "\n",
    "With this very simple shape of graph-data (directed edge = \"job\" -> \"work hours\"), the accuracy remains 75% for train, valid and test data.\n",
    "\n",
    "It confirms us that the training through basic GNN, on basic shaped data, delivers here stable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad55b8b",
   "metadata": {},
   "source": [
    "# Visual Representation of the Graph\n",
    "Here, we will seek for a visual representation of the (directed acyclic?) graph. The goal is to check if it corresponds to the users' intuition - at least regarding the \"non sense\" causal paths. \n",
    "\n",
    "Here, the edges have been built with the directed path **sex -> education** (recall that the link [potentially] exists, because we voluntarily biased the data to be \"sexist\" regarding the distribution of incomes). Hence, the non-sense we don't want to find is an impact of education on sex. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "29cff6e8",
   "metadata": {},
   "source": [
    "# pip install --force-reinstall -v \"scipy==1.8\"\n",
    "!pip install --upgrade scipy networkx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0f06ea9",
   "metadata": {},
   "source": [
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84bfd5ac",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "network_valid = to_networkx(data=data_valid)\n",
    "\n",
    "# subax1 = plt.subplot(121)\n",
    "\n",
    "# graph \n",
    "nx.draw(network_valid, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ea1d478",
   "metadata": {},
   "source": [
    "list_col_names = [\"occupation\", \"hours-per-week\"]#, \"sex\",\"education\"]\n",
    "\n",
    "data_job_valid = table_to_graph(X=X_valid, Y=Y_valid, list_col_names=list_col_names, edges=edges_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "482bfb8d",
   "metadata": {},
   "source": [
    "data_valid.x.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "198f6a1d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# create a representation of the edge (\"sex -> education\") \n",
    "# with only 2 values of education and 20 individuals (min, max)\n",
    "\n",
    "X_valid.reset_index(drop=True, inplace=True)\n",
    "Y_valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_education_max = X_valid.loc[X_valid[\"education\"]==X_valid[\"education\"].max()].iloc[:10]\n",
    "#df_education_min = X_valid.loc[X_valid[\"education\"]==X_valid[\"education\"].min()].iloc[:10]\n",
    "\n",
    "X_education_extreme = df_education_max#.append(df_education_min).sort_index()\n",
    "Y_education_extreme = Y_valid.iloc[X_education_extreme.index]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f741c5b",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals \n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\", \"education\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14eed2ad",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51e7af37",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6417b7f5",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = ['capital-gain', 'capital-loss',\n",
    "       'hours-per-week', 'workclass', 'education', 'marital-status',\n",
    "       'occupation', 'relationship', 'race', 'sex', 'native-country',\n",
    "       'clients_id'] # to take only the likely 'relevant' features 'age', 'fnlwgt', 'education-num' as node\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=['sex'])\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dc763f5",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = ['age', 'fnlwgt', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week', 'workclass', 'education', 'marital-status',\n",
    "       'occupation', 'relationship', 'race', 'sex', 'native-country',\n",
    "       'clients_id'] # to take only the likely 'relevant' feature 'education-num' as node\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=['sex'])\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939edc4",
   "metadata": {},
   "source": [
    "Obviously, we have no clear intuition of what these links do correspond with... By individual, path from the sex to the income? But there are more groups than individuals here selected (10)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5823877",
   "metadata": {},
   "source": [
    "## Constitute a graph - Try to connect the features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76781366",
   "metadata": {},
   "source": [
    "Here, we proceed in 2 steps (back and forth)\n",
    "\n",
    "1. **Detect the relations**\n",
    "We use the partial dependance plots to inspect the correlations (pers) sufficient? Input intervention changes?\n",
    "\n",
    "1. **Select the causal direction**\n",
    "Based on the user's experience and expertise (e.g. sex -> education, because the contrary would be logically and temporally impossible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550aa49",
   "metadata": {},
   "source": [
    "At a first sight, look at correlated features (!) may be some hidden correlations => experience is still required at this stage:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbb1e188",
   "metadata": {},
   "source": [
    "# reconstitute the dataset to check the correlations\n",
    "\n",
    "data_train_valid = X_train_valid.copy()\n",
    "data_train_valid['target'] = Y_train_valid\n",
    "data_train_valid"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b58d05a9",
   "metadata": {},
   "source": [
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(data_train_valid.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79e50761",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)    \n",
    "g = sns.pairplot(X_train_valid.filter(items=['education-num','education']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03d62be6",
   "metadata": {},
   "source": [
    "g = sns.pairplot(X_train_valid.filter(items=['sex','age']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7028b1fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "823a5db3",
   "metadata": {},
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# detect the relations: show the changes in predictions for the combinations of 2 features\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "f_names = [('sex', 'education')]\n",
    "# Similar to previous PDP plot except we use tuple of features instead of single feature\n",
    "disp4 = PartialDependenceDisplay.from_estimator(model, X_valid, f_names, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
