{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e3b2f2",
   "metadata": {},
   "source": [
    "# GCN on Census - training with batches (neighbor sampling method)\n",
    "There is an example of using a GCN on a tabular dataset for binary classification (here, Census to detect the people earning > $50_000). We suppose we already have some **logically consistent arrows** (coming from logical analysis of data -> all the coherent DAGs), that we want the GCN to learn - **phase 2** . \n",
    "\n",
    "**Causal hierarchy** could be introduced in the [definition of neighbors](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/loader/neighbor_loader.html#NeighborLoader) to build the subgraphs (i.e. batches of DataLoader)? \n",
    "\n",
    "Maybe: to specify the different \"relations\", we need to build a [heterogeneous graph](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py)? \n",
    "Begin with these constraints:\n",
    "    - Graph data 1: edge \"sex\"\n",
    "    - Graph data 2: edge \"work -> hours of work\"\n",
    "    - Graph data 1 -> (inherits from; temporal?) Graph data 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2affb517",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "In this notebook, we inspect **in which way a tabular dataset as Census can be used by an AI based on graphs to estimate wealthiness of individuals**. \n",
    "\n",
    "Therefore, we proceed in 2 steps:\n",
    "\n",
    "**1. We prepare data to be handled by a model based on a graph**\n",
    "We transform them into a graph, that involves strong assumptions on the features involved in connections...\n",
    "\n",
    "**2. We train an AI based on graphs**\n",
    "Here, we begin with a Graphical Neural Network (GNN) based on a Multi-Layer Perceptron (MLP), requiring the library Torch.\n",
    "\n",
    "**3. We inspect if the graph-based AI indeed reflects common & expert knowledge on**\n",
    "In particular, regarding the non-sense of certain inferences that should absolutely be avoided (e.g. education may influence occupation, but not the reverse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Data preparation for binary classification with graphs (Census)\n",
    "For this reshaping (and also interpretation, see below the choice of edges) of data tables to graphs, we used a basic Google [colab](https://colab.research.google.com/drive/1_eR7DXBF3V4EwH946dDPOxeclDBeKNMD?usp=sharing#scrollTo=WuggdIItffpv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03693",
   "metadata": {},
   "source": [
    "## General preparation - handle categorical features\n",
    "Here, we handle the categorical features through label-encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676925f",
   "metadata": {},
   "source": [
    "As we need to install torch-scatter and torch-sparse to enable torch_geometric (enabling our transformation of data in table, and the GNN), which seem not compatible with GPU on poetry, we use a [trick](https://stackoverflow.com/questions/74823704/error-building-wheel-for-torch-sparse-error-installing-pytorch-geometric) to install them on notebook with pip (to be cleaned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771274e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "try:\n",
    "    import torch_geometric\n",
    "except ModuleNotFoundError:\n",
    "    TORCH = torch.__version__.split(\"+\")[0]\n",
    "    CUDA = \"cu\" + torch.version.cuda.replace(\".\",\"\")\n",
    "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "#!pip install torch-geometric\n",
    "#import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import time\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from classif_basic.data_preparation import handle_cat_features, train_valid_test_split\n",
    "\n",
    "from classif_basic.graph import table_to_graph, add_new_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124240e",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a741869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset on clients for binary classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target == '>50K') * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7180da",
   "metadata": {},
   "source": [
    "### Add pre-processing: split hours-per-week in 2 quantiles, to use it as an edge (combined with \"occupation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7347572",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"hours-per-week\"].value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52305d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hours = X[\"hours-per-week\"].median() # '1' if the client works over 40 hours per week\n",
    "\n",
    "X[\"hours-per-week\"] = (X[\"hours-per-week\"] == median_hours).astype(int)\n",
    "X[\"hours-per-week\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99abfa",
   "metadata": {},
   "source": [
    "## Reshape (by interpreting) data to a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756db59",
   "metadata": {},
   "source": [
    "From this dataset (where we introduced selectively a \"sexist\" effect against women), let's see how we could swith from the tabular data to a graph representation.\n",
    "\n",
    "The point is that our features X all seem to be attributes of the clients, though we should find a way of representing their interactions between clients \n",
    "\n",
    "X = {race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, occupation, hours per week, workclass, race, sex, capital gain, capital loss, native country} \n",
    "\n",
    "**Nodes** \n",
    "Bank clients (by ID)\n",
    "\n",
    "**Edges** \n",
    "Here, we should find one or several ways of connecting the clients\n",
    "\n",
    "Should be occupation → if changes of occupation (or similar client with new occupation), which impact on the revenue? // change of football team => impact on the football rate \n",
    "(pers) actionable => predict revenue when switches to a new job??\n",
    "→ may be: “hours per week” <=> inspect the change of revenue if switches to greater hours per week?\n",
    "\n",
    "**Node Features** \n",
    "Attributs of the nodes, i.e. characteristics of the clients (here, hard to separate from what \"connects\" them...) \n",
    "\n",
    "Race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, hours per week, workclass, race, sex, capital gain, capital loss, native country \n",
    "\n",
    "**Label (here at a node-level?)** \n",
    "Income (Y = income > $50 000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f6878e",
   "metadata": {},
   "source": [
    "Test of my idea: create graphs with different edges, here sex (graph 1) -> education (graph 2)?\n",
    "\n",
    "Or enforce causal hierarchy through the neighborhood definition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faf0c92",
   "metadata": {},
   "source": [
    "As it is in use in the creation of batches by neighbors with PyTorch Geometric, we split the data inside the function and keep their train/valid/test masks (i.e. boolean tensor indicating if the individual is in X_train/X_valid/X_test).\n",
    "\n",
    "As for instance, data_total.train_mask will be required to pass in \"input_nodes\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba30f2",
   "metadata": {},
   "source": [
    "## Split between data used for GNN training / test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 7\n",
    "VALID_SIZE = 0.15\n",
    "preprocessing_cat_features = \"label_encoding\"\n",
    "\n",
    "X = handle_cat_features(X=X, preprocessing_cat_features=preprocessing_cat_features)\n",
    "\n",
    "# Split valid set for early stopping & model selection\n",
    "# \"stratify=Y\" to keep the same proportion of target classes in train/valid (i.e. model) and test sets \n",
    "X_model, X_test, Y_model, Y_test = train_test_split(\n",
    "    X, Y, test_size=VALID_SIZE, random_state=SEED, stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e527d61",
   "metadata": {},
   "source": [
    "## Transformation of model / test data into graphs with the same attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2960cf",
   "metadata": {},
   "source": [
    "First, shape the data used for GNN training in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabcd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute edge by hands: create our own edge combination, to predict the income - with directed paths\n",
    "# first edge joins \"occupation\" -> \"hours-per-week\"\n",
    "# second edge joins \"sex\" -> \"education\"\n",
    "X_total = X_model\n",
    "Y_total = Y_model\n",
    "\n",
    "list_col_names=[\"occupation\", \"hours-per-week\"] # test the model with only 2 categories (> or < median of work hours)\n",
    "\n",
    "edges_total = add_new_edge(data=X_total, previous_edge=None, list_col_names=[\"occupation\", \"hours-per-week\"])\n",
    "#edges_total = add_new_edge(data=X_total, previous_edge=edges_total, list_col_names=[\"sex\",\"education\"]\n",
    "\n",
    "# for training by specifying \"masks\" (i.e. boolean for nodes = individuals selected to train the GNN), \n",
    "# add a specification on train indexes \n",
    "data_total = table_to_graph(X=X_total, Y=Y_total, list_col_names=list_col_names, edges=edges_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a07489",
   "metadata": {},
   "source": [
    "Do exactly the same for test data (will be used for GNN test evaluation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_names=[\"occupation\", \"hours-per-week\"] # test the model with only 2 categories (> or < median of work hours)\n",
    "\n",
    "edges_test = add_new_edge(data=X_test, previous_edge=None, list_col_names=[\"occupation\", \"hours-per-week\"])\n",
    "#edges_test = add_new_edge(data=X_test, previous_edge=edges_test, list_col_names=[\"sex\",\"education\"]\n",
    "\n",
    "# for training by specifying \"masks\" (i.e. boolean for nodes = individuals selected to train the GNN), \n",
    "# add a specification on train indexes \n",
    "data_test = table_to_graph(X=X_test, Y=Y_test, list_col_names=list_col_names, edges=edges_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95addf5",
   "metadata": {},
   "source": [
    "# Train a sequential GNN learning causal hierarchy (small data)\n",
    "\n",
    "For faster training, avoiding to split data into batches (next step if it works), we here train the GNN on test_data (small data). \n",
    "\n",
    "1st layer: edge_index of 'sex'\n",
    "2nd layer: 'discovers' the edge_index of 'job' -> 'work hours'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db9bb3",
   "metadata": {},
   "source": [
    "## First approach: only changing the specified edge\n",
    "\n",
    "It works still with 76% of accuracy, but a problem is that only changing the edge (from sex -> job) does not involve that the GNN \"learns\" sex to be the causal ancestor...\n",
    "\n",
    "In particular, the **node features** are causal childs (education, job...) that already exist in the first \"ancestor\" layer."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7523a355",
   "metadata": {},
   "source": [
    "# now, get the graph-data for edge 1 (sex)\n",
    "edges_test_sex = add_new_edge(data=X_test, previous_edge=None, list_col_names=[\"sex\"])\n",
    "\n",
    "data_test_sex = table_to_graph(X=X_test, Y=Y_test, list_col_names=list_col_names, edges=edges_test_sex)\n",
    "\n",
    "data_test_work = data_test # to clearly identify the \"layer 2\" edges"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd08fd8d",
   "metadata": {},
   "source": [
    "from classif_basic.graph import GCN, GCN_ancestor_edge, activate_gpu\n",
    "\n",
    "device = activate_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9ba60",
   "metadata": {},
   "source": [
    "Here, we only need to specify the \"parent\" and \"child\" indexes processed sequentially by the GNN => causal hierarchy between sex and work is integrated (at least, 76% accuracy on small data)? To further test with the GPU..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c1da4e4",
   "metadata": {},
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "classifier = GCN_ancestor(data_test_sex).to(device) # only ancestor information in initialization? OK if not used\n",
    "\n",
    "classifier.train()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# these data (nodes, targets) do not change with the edges\n",
    "data_test = data_test_sex.to(device)\n",
    "target = data_test.y.to(device)\n",
    "x = data_test.x.to(device)\n",
    "x_child = data_test_work.x.to(device)\n",
    "# then, pass the different edges\n",
    "# for learning of this causal hierarchy by the GCN\n",
    "edge_index = data_test_sex.edge_index.to(device)\n",
    "edge_index_child = data_test_work.edge_index.to(device)\n",
    "\n",
    "preds = classifier(\n",
    "    x=x, \n",
    "    x_child=x_child,\n",
    "    edge_index=edge_index, \n",
    "    edge_index_child=edge_index_child, \n",
    "    device=device)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c4c9a15",
   "metadata": {},
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "error_test = loss(preds, target)\n",
    "print(f\"\\nError on test: {error_test:.4f} \\n\")\n",
    "\n",
    "# compute overall train&valid accuracy\n",
    "_, preds_temp = torch.max(preds.data, 1)\n",
    "total = len(target)\n",
    "correct = (preds_temp == target).sum().item()\n",
    "print(f\"Test Accuracy = {round(correct / total, 2)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f9f1c",
   "metadata": {},
   "source": [
    "## Integrating \"new\" child knowledge of the world \n",
    "\n",
    "Here, we try to pass to the GNN 2 graph-data\n",
    "- ancestor: with only the ancestor nodes\n",
    "- child: ancestor + child nodes, adding as an edge \"ancestor -> child\"\n",
    "\n",
    "Constitute 2 graph-data parent/child, suggesting causality by adding child nodes (and also edge: parent -> child) in the child data.\n",
    "\n",
    "Problem: only 1 parent specified? Let's begin to see if it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_parent = [\"age\", \"race\", \"sex\", \"native-country\"]\n",
    "edge_parent = \"sex\"\n",
    "\n",
    "X_test_parent = X_test.filter(list_parent)\n",
    "\n",
    "# add \"sex\" as a connection (edge) between these ancestors features\n",
    "edges_test_parent = add_new_edge(data=X_test_parent, previous_edge=None, list_col_names=[edge_parent])\n",
    "\n",
    "# being an edge, \"sex\" must be removed from the nodes\n",
    "list_parent.remove(edge_parent)\n",
    "data_test_parent = table_to_graph(X=X_test_parent, Y=Y_test, list_col_names=list_parent, edges=edges_test_parent)\n",
    "data_test_parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7b046",
   "metadata": {},
   "source": [
    "Based on this ancestor \"blind knowledge\", add the child as node features (and also edge: parent -> child) in the child graph-data. Here the first child is \"education\" (following ages of life...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652227f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first simplify the categories of education, to be better computed as edges\n",
    "\n",
    "median_education = X_test[\"education\"].median() # '1' if the client works over 40 hours per week\n",
    "\n",
    "X_test[\"education\"] = (X_test[\"education\"] == median_education).astype(int)\n",
    "X_test[\"education\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_child1 = [\"age\", \"race\", \"sex\", \"native-country\", \"education\"]\n",
    "edge_parent = \"sex\"\n",
    "edge_child1 = \"education\"\n",
    "\n",
    "X_test_child1 = X_test.filter(list_child1)\n",
    "\n",
    "# add \"sex\" as a connection (edge) between these ancestors features\n",
    "edges_test_child1 = add_new_edge(data=X_test_child1, previous_edge=None, \n",
    "                                 list_col_names=[edge_parent, edge_child1])\n",
    "\n",
    "# being edges, \"sex\" and \"education\" and must be removed from the nodes\n",
    "list_child1.remove(edge_parent)\n",
    "list_child1.remove(edge_child1)\n",
    "\n",
    "data_test_child1 = table_to_graph(X=X_test_child1, Y=Y_test, list_col_names=list_child1, \n",
    "                                  edges=edges_test_child1)\n",
    "data_test_child1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_child2 = [\"age\", \"race\", \"sex\", \"native-country\", \"education\", \"workclass\"]\n",
    "edge_parent = \"sex\"\n",
    "edge_child1 = \"education\"\n",
    "edge_child2 = \"workclass\"\n",
    "\n",
    "X_test_child2 = X_test.filter(list_child2)\n",
    "\n",
    "# add \"sex\" as a connection (edge) between these ancestors features\n",
    "edges_test_child2 = add_new_edge(data=X_test_child2, previous_edge=None, \n",
    "                                 list_col_names=[edge_child1, edge_child2])\n",
    "\n",
    "# being edges, \"sex\" and \"education\" and must be removed from the nodes\n",
    "list_child2.remove(edge_parent)\n",
    "list_child2.remove(edge_child1)\n",
    "list_child2.remove(edge_child2)\n",
    "\n",
    "data_test_child2 = table_to_graph(X=X_test_child2, Y=Y_test, list_col_names=list_child2, \n",
    "                                  edges=edges_test_child2)\n",
    "data_test_child2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66068c00",
   "metadata": {},
   "source": [
    "Finish with the \"last\" descendants, to complete the node features in the last layer (!) TODO before, group the columns to avoid redundancy, while keeping input information (e.g. between education - education level)!!\n",
    "\n",
    "-> reduction analysis to be led"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b90196",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ascendants = [\"age\", \"race\", \"sex\", \"native-country\", \"education\", \"workclass\"]\n",
    "\n",
    "set_final_descendants = set(X_test.columns) - set(list_ascendants)\n",
    "set_final_descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a378471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we assume the last descendant features are the last non-listed columns (has to be deduced)\n",
    "# list_final_descendants = list(set_final_descendants)\n",
    "list_final_descendants = [ \n",
    "    'capital-gain',\n",
    "     # 'occupation', TODO merge information with 'workclass'\n",
    "     'marital-status',\n",
    "     'fnlwgt',\n",
    "     #'education-num', TODO merge information with 'education'\n",
    "     'hours-per-week',\n",
    "     'relationship',\n",
    "     'capital-loss',\n",
    "      edge_child2] # add edge_child2 at the end of the chain? TODO investigate\n",
    "\n",
    "edge_final_descendants = 'hours-per-week'\n",
    "\n",
    "X_test_final_descendants = X_test.filter(list_final_descendants)\n",
    "\n",
    "# add \"sex\" as a connection (edge) between these ancestors features\n",
    "edges_test_final_descendants = add_new_edge(data=X_test_final_descendants, previous_edge=None, \n",
    "                                 list_col_names=[edge_child2, edge_final_descendants]) \n",
    "                                # edge here: direction of the last child (\"workclass\") on these features\n",
    "                                # here, we even add the direction on 'hours-per-week' -> TODO investigate \n",
    "                                # if 'hours-per-week' works only if it has the same ascendant-level as the other node features here?\n",
    "\n",
    "list_final_descendants.remove(edge_child2)\n",
    "list_final_descendants.remove(edge_final_descendants)\n",
    "\n",
    "data_test_final_descendants = table_to_graph(X=X_test_final_descendants, Y=Y_test, list_col_names=list_final_descendants, \n",
    "                                  edges=edges_test_final_descendants)\n",
    "data_test_final_descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cac131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classif_basic.graph import activate_gpu\n",
    "\n",
    "device = activate_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e2b8f",
   "metadata": {},
   "source": [
    "Here, we inspect if an edge containing an information out of features attributes can be added\n",
    "\n",
    "Indeed, \n",
    "- data_parent only entails parent features (age, sex, race, origin)\n",
    "- edge_parent_child computes the neighborhoods (embeddings) between clients by adding the information \"work\"\n",
    "\n",
    "=> what if we added the causal descendant edges through causal layers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428cef56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from classif_basic.graph import GCN_ancestor_edges\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "classifier = GCN_ancestor_edges(data_test_parent).to(device) # only ancestor information in initialization? OK if not used\n",
    "\n",
    "classifier.train()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# these data (nodes, targets) do not change with the edges\n",
    "data_test = data_test_parent.to(device)\n",
    "target = data_test_parent.y.to(device)\n",
    "\n",
    "x_parent = data_test_parent.x.to(device)\n",
    "x_child1 = data_test_child1.x.to(device)\n",
    "x_child2 = data_test_child2.x.to(device)\n",
    "x_final_descendants = data_test_final_descendants.x.to(device)\n",
    "\n",
    "# then, pass the different edges\n",
    "# for learning of this causal hierarchy by the GCN\n",
    "edge_index_parent = data_test_parent.edge_index.to(device)\n",
    "edge_index_child1 = data_test_child1.edge_index.to(device)\n",
    "edge_index_child2 = data_test_child2.edge_index.to(device)\n",
    "edge_index_final_descendants = data_test_final_descendants.edge_index.to(device)\n",
    "\n",
    "preds = classifier(\n",
    "    x_parent=x_parent,\n",
    "    x_child1=x_child1,\n",
    "    x_child2=x_child2,\n",
    "    x_final_descendants=x_final_descendants,\n",
    "    edge_index_parent=edge_index_parent,\n",
    "    edge_index_child1=edge_index_child1, \n",
    "    edge_index_child2=edge_index_child2,\n",
    "    edge_index_final_descendants=edge_index_final_descendants,\n",
    "    device=device)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "error_test = loss(preds, target)\n",
    "print(f\"\\nError on test: {error_test:.4f} \\n\")\n",
    "\n",
    "# compute overall train&valid accuracy\n",
    "_, preds_temp = torch.max(preds.data, 1)\n",
    "total = len(target)\n",
    "correct = (preds_temp == target).sum().item()\n",
    "print(f\"Test Accuracy = {round(correct / total, 2)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b5cd3",
   "metadata": {},
   "source": [
    "# Train a basic Graph Neural Network on the graph-shaped data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cde5a",
   "metadata": {},
   "source": [
    "## Train with batches (neighborhood sampling) a basic GCN \n",
    "\n",
    "Here, we try using the batches constituted from neighborhoods to train the GNN, using our GPU (if accessed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d146d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classif_basic.graph import train_GNN\n",
    "\n",
    "gnn_basic = train_GNN(\n",
    "                data_total=data_total,\n",
    "                loader_method=\"neighbor_nodes\",\n",
    "                batch_size = 32,\n",
    "                epoch_nb = 2,\n",
    "                learning_rate = 0.01,\n",
    "                nb_neighbors_per_sample = 30,\n",
    "                nb_iterations_per_neighbors = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32385c",
   "metadata": {},
   "source": [
    "## Inspect the predictions of the model on valid and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b56e7a",
   "metadata": {},
   "source": [
    "Let's inspect the model on test data, to assess if the stability of performance is not due to coincidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109cc85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from classif_basic.graph import evaluate_gnn\n",
    "\n",
    "classifier=gnn_basic\n",
    "data_test=data_test\n",
    "loss_name=\"cross_entropy\"\n",
    "\n",
    "# unfortunately, memory error... Evaluate per batches? Or create an independant data_test? // Evaluate on valid \n",
    "\n",
    "evaluate_gnn(\n",
    "    classifier=gnn_basic, \n",
    "    data_test=data_test, \n",
    "    loss_name=loss_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f7e6a",
   "metadata": {},
   "source": [
    "**No Overfitting**\n",
    "\n",
    "With this very simple shape of graph-data (directed edge = \"job\" -> \"work hours\"), the accuracy remains 75% for train, valid and test data.\n",
    "\n",
    "It confirms us that the training through basic GNN, on basic shaped data, delivers here stable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad55b8b",
   "metadata": {},
   "source": [
    "# Visual Representation of the Graph\n",
    "Here, we will seek for a visual representation of the (directed acyclic?) graph. The goal is to check if it corresponds to the users' intuition - at least regarding the \"non sense\" causal paths. \n",
    "\n",
    "Here, the edges have been built with the directed path **sex -> education** (recall that the link [potentially] exists, because we voluntarily biased the data to be \"sexist\" regarding the distribution of incomes). Hence, the non-sense we don't want to find is an impact of education on sex. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "29cff6e8",
   "metadata": {},
   "source": [
    "# pip install --force-reinstall -v \"scipy==1.8\"\n",
    "!pip install --upgrade scipy networkx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0f06ea9",
   "metadata": {},
   "source": [
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84bfd5ac",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "network_valid = to_networkx(data=data_valid)\n",
    "\n",
    "# subax1 = plt.subplot(121)\n",
    "\n",
    "# graph \n",
    "nx.draw(network_valid, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ea1d478",
   "metadata": {},
   "source": [
    "list_col_names = [\"occupation\", \"hours-per-week\"]#, \"sex\",\"education\"]\n",
    "\n",
    "data_job_valid = table_to_graph(X=X_valid, Y=Y_valid, list_col_names=list_col_names, edges=edges_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "482bfb8d",
   "metadata": {},
   "source": [
    "data_valid.x.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "198f6a1d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# create a representation of the edge (\"sex -> education\") \n",
    "# with only 2 values of education and 20 individuals (min, max)\n",
    "\n",
    "X_valid.reset_index(drop=True, inplace=True)\n",
    "Y_valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_education_max = X_valid.loc[X_valid[\"education\"]==X_valid[\"education\"].max()].iloc[:10]\n",
    "#df_education_min = X_valid.loc[X_valid[\"education\"]==X_valid[\"education\"].min()].iloc[:10]\n",
    "\n",
    "X_education_extreme = df_education_max#.append(df_education_min).sort_index()\n",
    "Y_education_extreme = Y_valid.iloc[X_education_extreme.index]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f741c5b",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals \n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\", \"education\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14eed2ad",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51e7af37",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6417b7f5",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = ['capital-gain', 'capital-loss',\n",
    "       'hours-per-week', 'workclass', 'education', 'marital-status',\n",
    "       'occupation', 'relationship', 'race', 'sex', 'native-country',\n",
    "       'clients_id'] # to take only the likely 'relevant' features 'age', 'fnlwgt', 'education-num' as node\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=['sex'])\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dc763f5",
   "metadata": {},
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = ['age', 'fnlwgt', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week', 'workclass', 'education', 'marital-status',\n",
    "       'occupation', 'relationship', 'race', 'sex', 'native-country',\n",
    "       'clients_id'] # to take only the likely 'relevant' feature 'education-num' as node\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=['sex'])\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939edc4",
   "metadata": {},
   "source": [
    "Obviously, we have no clear intuition of what these links do correspond with... By individual, path from the sex to the income? But there are more groups than individuals here selected (10)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5823877",
   "metadata": {},
   "source": [
    "## Constitute a graph - Try to connect the features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76781366",
   "metadata": {},
   "source": [
    "Here, we proceed in 2 steps (back and forth)\n",
    "\n",
    "1. **Detect the relations**\n",
    "We use the partial dependance plots to inspect the correlations (pers) sufficient? Input intervention changes?\n",
    "\n",
    "1. **Select the causal direction**\n",
    "Based on the user's experience and expertise (e.g. sex -> education, because the contrary would be logically and temporally impossible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550aa49",
   "metadata": {},
   "source": [
    "At a first sight, look at correlated features (!) may be some hidden correlations => experience is still required at this stage:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbb1e188",
   "metadata": {},
   "source": [
    "# reconstitute the dataset to check the correlations\n",
    "\n",
    "data_train_valid = X_train_valid.copy()\n",
    "data_train_valid['target'] = Y_train_valid\n",
    "data_train_valid"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b58d05a9",
   "metadata": {},
   "source": [
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(data_train_valid.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79e50761",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)    \n",
    "g = sns.pairplot(X_train_valid.filter(items=['education-num','education']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03d62be6",
   "metadata": {},
   "source": [
    "g = sns.pairplot(X_train_valid.filter(items=['sex','age']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7028b1fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "823a5db3",
   "metadata": {},
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# detect the relations: show the changes in predictions for the combinations of 2 features\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "f_names = [('sex', 'education')]\n",
    "# Similar to previous PDP plot except we use tuple of features instead of single feature\n",
    "disp4 = PartialDependenceDisplay.from_estimator(model, X_valid, f_names, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
