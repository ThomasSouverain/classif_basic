{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2affb517",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "In this notebook, we inspect **in which way a tabular dataset as Census can be used to compute a structural causal model (or a model based on causally structured representation of features & data) to estimate wealthiness of individuals**. \n",
    "\n",
    "Therefore, we proceed in 4 steps:\n",
    "\n",
    "**1. Find the 'latent' variables**\n",
    "E.g. 'seniority' that could be an unobserved confounder else, if we draw a  \n",
    "\n",
    "**2. Constitute a directed acyclic graph with all features (Census + latent-reconstituted)**\n",
    "Based on the finding (and, more, interpretation) of latent features, we will build a coherent representation of systematic influences between the features of Census (here, to estimate the incomes of clients). \n",
    "\n",
    "**3. Build a Structural Causal Model computing their influences**\n",
    "\n",
    "**4. We inspect if the graph-based AI indeed reflects common & expert knowledge on**\n",
    "In particular, regarding the non-sense of certain inferences that should absolutely be avoided (e.g. education may influence occupation, but not the reverse).\n",
    "\n",
    "Through Input Intervention Changes?\n",
    "\n",
    "Or, build a model learning on (i) causal paths stated in (2) and (ii) data ? Would be (3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5582cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Find the 'latent' variables (Census)\n",
    "To 'complete' our causal paths representing the features used to infer the incomes of individuals, we used factor analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03693",
   "metadata": {},
   "source": [
    "## General data preparation - handle categorical features\n",
    "Here, we handle the categorical features through label-encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bad479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 00:23:23.070487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-15 00:23:23.879171: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 00:23:23.879227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 00:23:23.879236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import time\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from classif_basic.data_preparation import train_valid_test_split, set_target_if_feature, automatic_preprocessing\n",
    "\n",
    "from classif_basic.graph import table_to_graph, add_new_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124240e",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "Fix precise % of population distribution (sex: Male, Female) and % of wealthiness according to sex. In that way, we could inspect if the structure of the model (here based on a graph) integrates this \"sexist\" representation of the world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a741869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset on clients for binary classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target)# == '>50K') * 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5571364b",
   "metadata": {},
   "source": [
    "dataset = X.copy()\n",
    "dataset['target'] = Y\n",
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d29a743",
   "metadata": {},
   "source": [
    "# here, \"treatment\" is saw as being 'Male' and not 'Female'\n",
    "\n",
    "df_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==1)]\n",
    "df_no_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==0)]\n",
    "df_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==1)]\n",
    "df_no_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==0)]\n",
    "\n",
    "print(df_response_if_feature.shape[0])\n",
    "print(df_no_response_if_feature.shape[0])\n",
    "print(df_response_if_not_feature.shape[0])\n",
    "print(df_no_response_if_not_feature.shape[0])\n",
    "\n",
    "\n",
    "# % of men selected by the initial data\n",
    "df_response_if_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_feature.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3578141",
   "metadata": {},
   "source": [
    "# % of women selected by the initial data\n",
    "df_response_if_not_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_not_feature.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4256010",
   "metadata": {},
   "source": [
    "len_dataset = 20_000\n",
    "\n",
    "percentage_feature= 70\n",
    "percentage_response_if_feature=70\n",
    "percentage_response_if_not_feature=10\n",
    "\n",
    "sexist_dataset = set_target_if_feature(\n",
    "    df_response_if_feature=df_response_if_feature,\n",
    "    df_no_response_if_feature=df_no_response_if_feature,\n",
    "    df_response_if_not_feature=df_response_if_not_feature,\n",
    "    df_no_response_if_not_feature=df_no_response_if_not_feature,\n",
    "    len_dataset=len_dataset,\n",
    "    percentage_feature=percentage_feature,\n",
    "    percentage_response_if_feature=percentage_response_if_feature,\n",
    "    percentage_response_if_not_feature=percentage_response_if_not_feature)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a98680d",
   "metadata": {},
   "source": [
    "X = sexist_dataset.loc[: , dataset.columns != 'target']\n",
    "Y = sexist_dataset['target']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcf58625",
   "metadata": {},
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447f8c",
   "metadata": {},
   "source": [
    "### Train-test-split, to prepare for 3 graphs representing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e01c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task = \"regression\" #\"classification\"\n",
    "preprocessing_cat_features = \"label_encoding\"\n",
    "\n",
    "X_train, X_valid, X_train_valid, X_test, Y_train, Y_valid, Y_train_valid, Y_test = train_valid_test_split(\n",
    "    X=X,\n",
    "    Y=Y, \n",
    "    model_task=model_task,\n",
    "    preprocessing_cat_features=preprocessing_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d12359",
   "metadata": {},
   "source": [
    "## Factor Analysis\n",
    "Here, we base on the sklearn implementation (https://scikit-learn.org/stable/modules/decomposition.html#fa)\n",
    "\n",
    "Read more here, may be Bayesian approach?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddb0844c",
   "metadata": {},
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "N = 100\n",
    "eta1 = np.random.normal(size=N)\n",
    "eta2 = np.random.normal(size=N)\n",
    "eta1 += 0.3 * eta2\n",
    "\n",
    "y1 = np.random.normal(size=N, scale=0.5) + eta1\n",
    "y2 = np.random.normal(size=N, scale=0.5) + 2 * eta1\n",
    "y3 = np.random.normal(size=N, scale=0.5) + 3 * eta1 + eta2\n",
    "y4 = np.random.normal(size=N, scale=0.5) - eta2\n",
    "y5 = np.random.normal(size=N, scale=0.5) + 1.5 * eta2\n",
    "x = np.random.normal(size=N)\n",
    "data = pd.DataFrame([y1, y2, y3, y4, y5, x],\n",
    "                    index=['y1', 'y2', 'y3', 'y4', 'y5', 'x']).T\n",
    "\n",
    "print(semopy.efa.explore_cfa_model(data))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1824b69",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "X_valid_small = X_valid.reset_index(drop=True).loc[:99] # test with only 100 individuals\n",
    "# no result because no perfect mathematical regression? To be confirmed \n",
    "\n",
    "semopy.efa.explore_cfa_model(X_valid_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69693b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with the number of already present features, to add one to find 'latent' variables\n",
    "nb_features_census = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fe91d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn import datasets\n",
    "\n",
    "my_fa = FactorAnalysis(n_components=nb_features_census-1, rotation='varimax') \n",
    "\n",
    "X_transformed = my_fa.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a1215c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6228, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e1edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6228, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f436e",
   "metadata": {},
   "source": [
    "Reduce dimensionality for features with redundant information (e.g. \"education\" - \"education-num\"), to put a more straightforward graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f03809c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8218     11\n",
       "39620    12\n",
       "14122    11\n",
       "29881     3\n",
       "25989    11\n",
       "         ..\n",
       "42023     9\n",
       "15862     1\n",
       "35399    11\n",
       "28047    11\n",
       "1588      9\n",
       "Name: education, Length: 6228, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[\"education\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f577ec6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8218      9.0\n",
       "39620    14.0\n",
       "14122     9.0\n",
       "29881     2.0\n",
       "25989     9.0\n",
       "         ... \n",
       "42023    13.0\n",
       "15862     7.0\n",
       "35399     9.0\n",
       "28047     9.0\n",
       "1588     13.0\n",
       "Name: education-num, Length: 6228, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[\"education-num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d881cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_to_one_factor = FactorAnalysis(n_components=1, rotation='varimax') \n",
    "\n",
    "unique_col_education = two_to_one_factor.fit_transform(X_valid.filter(items = [\"education\",\"education-num\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e856d",
   "metadata": {},
   "source": [
    "But it leads to a problem of interpretability... Indeed, what do the new features mean? Increase with higher level of education? I have no clues to guess that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475fd391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.13539022, -0.98097948, -0.49438924, -0.47984356, -0.1506015 ,\n",
       "       -0.03115703,  0.26311877,  0.53991143,  0.76425469,  1.12846302,\n",
       "        1.38777255,  1.64708208,  1.90639161,  2.04331921,  2.30262874,\n",
       "        2.56193827])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(unique_col_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e44ca81",
   "metadata": {},
   "source": [
    "Now, how to interpret it? A new column was built -> validate it through correlation with the other columns, if this correlation makes sense as the introduction of an intermediate variable (based on our domain-knowledge)? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46680d",
   "metadata": {},
   "source": [
    "# High-Level Causal Representation (Model) of data - Constitute a directed acyclic graph with all features\n",
    "\n",
    "Structural Causal Model to quantify the influences *given* directed causal paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20747812",
   "metadata": {},
   "source": [
    "Here, the goal is to **build a structural model that will then be learnt by AI** (from data, then with AI).\n",
    "\n",
    "To better investigate (and confirm according to experience and business knowledge) the paths inside the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5056c87",
   "metadata": {},
   "source": [
    "(!) discovering new relationships (and also features) will be a further step:\n",
    "\n",
    "We base on this [introducing article](https://towardsdatascience.com/structural-equation-modeling-dca298798f4d):\n",
    "\n",
    "\"Structural Equation Models give you estimates of coefficients based on the hypothesized relationships between variables. It cannot find other relationships than those that you specify... A great way to use Structural Equation Models is to provide multiple hypothetical models, estimate each of them, and then analyze the differences between them to work towards a better and better model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24896d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/work/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: fsspec in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (2023.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/work/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: s3fs in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (2023.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from s3fs) (3.8.4)\n",
      "Requirement already satisfied: fsspec==2023.1.0 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from s3fs) (2023.1.0)\n",
      "Requirement already satisfied: aiobotocore~=2.4.2 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from s3fs) (2.4.2)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiobotocore~=2.4.2->s3fs) (1.14.1)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiobotocore~=2.4.2->s3fs) (0.11.0)\n",
      "Requirement already satisfied: botocore<1.27.60,>=1.27.59 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiobotocore~=2.4.2->s3fs) (1.27.59)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.0.10)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.3)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from aioitertools>=0.5.1->aiobotocore~=2.4.2->s3fs) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.26.8)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.0.1)\n",
      "Requirement already satisfied: idna>=2.0 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/work/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: boto in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (2.49.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/work/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: semopy in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (2.3.9)\n",
      "Requirement already satisfied: pandas in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from semopy) (1.4.0)\n",
      "Requirement already satisfied: sklearn in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from semopy) (0.0)\n",
      "Requirement already satisfied: sympy in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from semopy) (1.11.1)\n",
      "Requirement already satisfied: scipy in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from semopy) (1.6.1)\n",
      "Requirement already satisfied: numpy in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from semopy) (1.22.1)\n",
      "Requirement already satisfied: statsmodels in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from semopy) (0.13.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from pandas->semopy) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from pandas->semopy) (2.8.2)\n",
      "Requirement already satisfied: scikit-learn in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from sklearn->semopy) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from statsmodels->semopy) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from statsmodels->semopy) (0.5.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from sympy->semopy) (1.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from packaging>=21.3->statsmodels->semopy) (3.0.7)\n",
      "Requirement already satisfied: six in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels->semopy) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from scikit-learn->sklearn->semopy) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages (from scikit-learn->sklearn->semopy) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.0 is available.\r\n",
      "You should consider upgrading via the '/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fsspec\n",
    "!pip install s3fs\n",
    "!pip install boto\n",
    "\n",
    "!pip install semopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "359fb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto\n",
    "import semopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6ef09",
   "metadata": {},
   "source": [
    "In cases of strong correlations, reduce to only one column? And control for native country (mostly US, hence take US and delete the column?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cada8ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020516691257224565"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for comparison, a case where the correlation should be irrelevant\n",
    "X_valid['education'].corr(X_valid['relationship'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aee45a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35942598961877636"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid['education'].corr(X_valid['education-num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db5d9680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17850429871918275"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid['relationship'].corr(X_valid['marital-status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb79f059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30823817891355526"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid['workclass'].corr(X_valid['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c08475e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06752629072839836"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid['hours-per-week'].corr(X_valid['capital-loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb079a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8218</th>\n",
       "      <td>59.0</td>\n",
       "      <td>172667.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39620</th>\n",
       "      <td>29.0</td>\n",
       "      <td>204516.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>60.0</td>\n",
       "      <td>495366.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29881</th>\n",
       "      <td>57.0</td>\n",
       "      <td>253914.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25989</th>\n",
       "      <td>19.0</td>\n",
       "      <td>128453.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42023</th>\n",
       "      <td>40.0</td>\n",
       "      <td>53835.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>22.0</td>\n",
       "      <td>289982.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35399</th>\n",
       "      <td>44.0</td>\n",
       "      <td>249332.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28047</th>\n",
       "      <td>44.0</td>\n",
       "      <td>204235.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>23.0</td>\n",
       "      <td>200593.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6228 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "8218   59.0  172667.0            9.0           0.0           0.0   \n",
       "39620  29.0  204516.0           14.0           0.0           0.0   \n",
       "14122  60.0  495366.0            9.0           0.0           0.0   \n",
       "29881  57.0  253914.0            2.0           0.0           0.0   \n",
       "25989  19.0  128453.0            9.0           0.0           0.0   \n",
       "...     ...       ...            ...           ...           ...   \n",
       "42023  40.0   53835.0           13.0           0.0           0.0   \n",
       "15862  22.0  289982.0            7.0           0.0           0.0   \n",
       "35399  44.0  249332.0            9.0           0.0           0.0   \n",
       "28047  44.0  204235.0            9.0           0.0           0.0   \n",
       "1588   23.0  200593.0           13.0           0.0           0.0   \n",
       "\n",
       "       hours_per_week  workclass  education  marital_status  occupation  \\\n",
       "8218             40.0          3         11               2          13   \n",
       "39620            15.0          6         12               2           9   \n",
       "14122            38.0          3         11               0           0   \n",
       "29881            35.0          5          3               2          11   \n",
       "25989            28.0          8         11               4          14   \n",
       "...               ...        ...        ...             ...         ...   \n",
       "42023            50.0          3          9               2          11   \n",
       "15862            40.0          3          1               4           7   \n",
       "35399            40.0          3         11               2          13   \n",
       "28047            40.0          3         11               2          13   \n",
       "1588             40.0          1          9               4           9   \n",
       "\n",
       "       relationship  race  sex  native_country income  \n",
       "8218              0     4    1              38  <=50K  \n",
       "39620             0     4    1              38  <=50K  \n",
       "14122             1     4    0              38  <=50K  \n",
       "29881             0     4    1              25  <=50K  \n",
       "25989             3     4    0              38  <=50K  \n",
       "...             ...   ...  ...             ...    ...  \n",
       "42023             0     4    1              38   >50K  \n",
       "15862             1     4    0              38  <=50K  \n",
       "35399             0     4    1               6  <=50K  \n",
       "28047             0     4    1              38  <=50K  \n",
       "1588              3     4    1              38  <=50K  \n",
       "\n",
       "[6228 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we begin to test this Structural Equation Modelling (SEM) approach on a small sample (X_valid)\n",
    "\n",
    "# and add the target (revenue) for future predictions\n",
    "# TODO why not a regression?\n",
    "data_valid = X_valid.copy()\n",
    "data_valid['income'] = Y_valid\n",
    "\n",
    "# adapt names of columns, to be compatible with semopy\n",
    "list_cols = data_valid.columns.to_list()\n",
    "list_cols = [feat.replace('-','_') for feat in list_cols]\n",
    "data_valid.columns = list_cols\n",
    "data_valid"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b246f4ab",
   "metadata": {},
   "source": [
    "model_spec = \"\"\"\n",
    "  # measurement model\n",
    "    JobPerf =~ ClientSat + SuperSat + ProjCompl\n",
    "    Social =~ PsychTest1 + PsychTest2\n",
    "    Intellect =~ YrsEdu + IQ\n",
    "    Motivation =~ HrsTrn + HrsWrk\n",
    "  # regressions\n",
    "    JobPerf ~ Social + Intellect + Motivation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c65496",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = \"\"\"\n",
    "  # measurement part\n",
    "    labour_income =~ marital_status + occupation + hours_per_week\n",
    "    capital_income =~ capital_loss + capital_gain \n",
    "    \n",
    "  # structural part\n",
    "\n",
    "    relationship ~ education + sex\n",
    "    marital_status ~ relationship\n",
    "    \n",
    "    fnlwgt ~ race + sex + native_country + age\n",
    "    occupation ~ education + age + fnlwgt \n",
    "    workclass ~ occupation \n",
    "    hours_per_week ~ occupation + workclass\n",
    "    capital_loss ~ age + fnlwgt + occupation\n",
    "    capital_gain ~ age + fnlwgt + occupation + hours_per_week\n",
    "    \n",
    "    income ~ labour_income + capital_income\n",
    "\"\"\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = semopy.Model(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d93ccfe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model using the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_valid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages/semopy/model.py:1099\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, data, cov, obj, solver, groups, clean_slate, regularization, n_samples, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLW\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSLSQP\u001b[39m\u001b[38;5;124m'\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1057\u001b[0m         clean_slate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, regularization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m    Fit model to data.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \n\u001b[1;32m   1098\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m              \u001b[49m\u001b[43mclean_slate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_slate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIML\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmx_data\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages/semopy/model.py:1040\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(self, data, cov, groups, clean_slate, n_samples)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariables \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m are missing from data.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(t))\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_cov(cov)\n",
      "File \u001b[0;32m/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages/semopy/model.py:902\u001b[0m, in \u001b[0;36mModel.load_data\u001b[0;34m(self, data, covariance, groups)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmx_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmx_data[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mordinal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvars:\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_cov(covariance\u001b[38;5;241m.\u001b[39mloc[obs, obs]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 902\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m covariance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmx_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     inds \u001b[38;5;241m=\u001b[39m [obs\u001b[38;5;241m.\u001b[39mindex(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvars[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mordinal\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/work/.cache/poetry/classif-basic-DJpFP61h-py3.8/lib/python3.8/site-packages/semopy/utils.py:100\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcov\u001b[39m(x: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    Compute covariance matrix takin in account missing values.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     masked_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39marray(x, mask\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    101\u001b[0m     cov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mcov(masked_x, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rowvar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cov\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# Fit the model using the data\n",
    "model.fit(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015b754",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show the results using the inspect method\n",
    "model.inspect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09b4a464",
   "metadata": {},
   "source": [
    "# extra step to allow graphviz to be found \n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + '/work/notebooks/Anaconda3/envs/keras/Library/bin/graphviz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "g = graphviz.Digraph('G')#, format=ext, engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1152159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semplot(mod, filename, \n",
    "            plot_exos=True, engine='dot', latshape='circle',\n",
    "            plot_ests=True, show=False):\n",
    "\n",
    "    inspection = mod.inspect(std_est=False)\n",
    "    \n",
    "    images = dict()\n",
    "    \n",
    "    t = filename.split('.')\n",
    "    filename, ext = '.'.join(t[:-1]), t[-1]\n",
    "    g = graphviz.Digraph('G', format=ext, engine=engine)\n",
    "    \n",
    "    g.attr(overlap='scale', splines='true')\n",
    "    g.attr('edge', fontsize='12')\n",
    "    g.attr('node', shape=latshape, fillcolor='#cae6df', style='filled')\n",
    "    for lat in mod.vars['latent']:\n",
    "        if lat in images:\n",
    "            g.node(lat, label='', image=images[lat])\n",
    "        else:\n",
    "            g.node(lat, label=lat)\n",
    "    \n",
    "    g.attr('node', shape='box', style='')\n",
    "    for obs in mod.vars['observed']:\n",
    "        if obs in images:\n",
    "            g.node(obs, label='', image=images[obs])\n",
    "        else:\n",
    "            g.node(obs, label=obs)\n",
    "\n",
    "    regr = inspection[inspection['op'] == '~']\n",
    "    all_vars = mod.vars['all']\n",
    "    try:\n",
    "        exo_vars = mod.vars['observed_exogenous']\n",
    "    except KeyError:\n",
    "        exo_vars = set()\n",
    "    for _, row in regr.iterrows():\n",
    "        lval, rval, est = row['lval'], row['rval'], row['Estimate']\n",
    "        if (rval not in all_vars) or (~plot_exos and rval in exo_vars) or\\\n",
    "            (rval == '1'):\n",
    "            continue\n",
    "        if plot_ests:\n",
    "            pval = row['p-value']\n",
    "            label = '{:.3f}'.format(float(est))\n",
    "            if pval !='-':\n",
    "                label += r'\\np-val: {:.2f}'.format(float(pval))\n",
    "        else:\n",
    "            label = str()\n",
    "        g.edge(rval, lval, label=label)\n",
    "\n",
    "    #g.render(filename, view=show)        \n",
    "    #g.render(view=show)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb147961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "semplot(model, \"high_level_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99abfa",
   "metadata": {},
   "source": [
    "## Previous Work (Causal Graph) - Reshape (by interpreting) data to a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756db59",
   "metadata": {},
   "source": [
    "From this dataset (where we introduced selectively a \"sexist\" effect against women), let's see how we could swith from the tabular data to a graph representation.\n",
    "\n",
    "The point is that our features X all seem to be attributes of the clients, though we should find a way of representing their interactions between clients \n",
    "\n",
    "X = {race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, occupation, hours per week, workclass, race, sex, capital gain, capital loss, native country} \n",
    "\n",
    "**Nodes** \n",
    "Bank clients (by ID)\n",
    "\n",
    "**Edges** \n",
    "Here, we should find one or several ways of connecting the clients\n",
    "\n",
    "Should be occupation â†’ if changes of occupation (or similar client with new occupation), which impact on the revenue? // change of football team => impact on the football rate \n",
    "(pers) actionable => predict revenue when switches to a new job??\n",
    "â†’ may be: â€œhours per weekâ€ <=> inspect the change of revenue if switches to greater hours per week?\n",
    "\n",
    "**Node Features** \n",
    "Attributs of the nodes, i.e. characteristics of the clients (here, hard to separate from what \"connects\" them...) \n",
    "\n",
    "Race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, hours per week, workclass, race, sex, capital gain, capital loss, native country \n",
    "\n",
    "**Label (here at a node-level?)** \n",
    "Income (Y = income > $50 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute edge by hands: create our own edge combination, to predict the income - with directed paths\n",
    "# first edge joins \"occupation\" -> \"hours-per-week\"\n",
    "# second edge joins \"sex\" -> \"education\"\n",
    "\n",
    "edges_train = add_new_edge(data=X_train, previous_edge=None, list_col_names=[\"occupation\", \"hours-per-week\"])\n",
    "#edges_train = add_new_edge(data=X_train, previous_edge=edges_train, list_col_names=[\"sex\",\"education\"])\n",
    "\n",
    "edges_valid = add_new_edge(data=X_valid, previous_edge=None, list_col_names=[\"occupation\", \"hours-per-week\"])\n",
    "#edges_valid = add_new_edge(data=X_valid, previous_edge=edges_valid, list_col_names=[\"sex\",\"education\"])\n",
    "\n",
    "edges_test = add_new_edge(data=X_test, previous_edge=None, list_col_names=[\"occupation\", \"hours-per-week\"])\n",
    "#edges_test = add_new_edge(data=X_test, previous_edge=edges_test, list_col_names=[\"sex\",\"education\"])\n",
    "\n",
    "# specify the feature(s) used to connect the clients in couples, i.e. to build the edge of the data graph\n",
    "\n",
    "list_col_names = [\"occupation\", \"hours-per-week\"]#, \"sex\",\"education\"]\n",
    "\n",
    "data_train = table_to_graph(X=X_train, Y=Y_train, list_col_names=list_col_names, edges=edges_train)\n",
    "data_valid = table_to_graph(X=X_valid, Y=Y_valid, list_col_names=list_col_names, edges=edges_valid)\n",
    "data_test = table_to_graph(X=X_test, Y=Y_test, list_col_names=list_col_names, edges=edges_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3587b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce74d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b5cd3",
   "metadata": {},
   "source": [
    "# Train a basic Graph Neural Network on the graph-shaped data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32385c",
   "metadata": {},
   "source": [
    "## Build a basic convolutional GNN with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ede7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here intervenes the quick \"introduction by example\" of GCN by torch\n",
    "# in 'https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html'\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, data.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f6f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_nb = 200\n",
    "\n",
    "t_basic_1 = time.time()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(data=data_train).to(device)\n",
    "data_train = data_train.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.double()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(batch_nb): \n",
    "    # better with 200 batches (with only feature \"occupation\" as edge, 70% accuracy vs 50% accuracy with 50 batches)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data_train)\n",
    "    loss = F.nll_loss(out, data_train.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "t_basic_2 = time.time()\n",
    "\n",
    "print(f\"Training of the basic GCN on Census with {batch_nb} batches took {(t_basic_2 - t_basic_1)/60} mn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d174f7",
   "metadata": {},
   "source": [
    "Finally, we can evaluate our model on the validation nodes. Obviously, linking the clients only through the job provides less than 70% of accuracy even on the train set. Therefore, we need to seek for other ways..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f2b23",
   "metadata": {},
   "source": [
    "By creating an edge only with the combination of sex and education, we observe an accuracy of 61% on train that does not fall down on valid (65%). Moreover, **when the graph is directed (sex -> education), the accuracy seems to increase** without falling down valid performance: + 11% on train (76%), +2% on valid (67%), and 70% on test.  \n",
    "\n",
    "Thanks to the training of the GCN with 200 batches, which however took 20 mn for 15_000 rows and 2 classes (and we shall admit, edge_index=[2, 10813909])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9794ede",
   "metadata": {},
   "source": [
    "**Other observations (tests of combinations of features as edges)**\n",
    "\n",
    "Having created our own edge index combining (sex&education) and (occupation), the training took 7 mn more (27 mn) but the performance did not improve (61% on train set...)\n",
    "\n",
    "Adding the combination (occupation -> hours-per-week) to (sex -> education) does not improve the performances, but it decreases it (60 +-2 % on train and valid). Maybe because (i) it complexifies too much the network (ii) the model or (iii) the model's hyperparameters (batch, layers...) is too simple to catch these relations (iii) the models? \n",
    "\n",
    "**Constitution of couples graph data - graph networks to be tested, with input intervention changes...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57509b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model(data_train).argmax(dim=1)\n",
    "nb_indivs_train = data_train.x.shape[0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct_train = (pred_train == data_train.y).sum()\n",
    "acc = int(correct_train) / nb_indivs_train\n",
    "print(f'Accuracy on train data: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7693ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_valid = model(data_valid).argmax(dim=1)\n",
    "nb_indivs_valid = data_valid.x.shape[0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct_valid = (pred_valid == data_valid.y).sum()\n",
    "acc = int(correct_valid) / nb_indivs_valid\n",
    "print(f'Accuracy on valid data: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b56e7a",
   "metadata": {},
   "source": [
    "Let's inspect the model on test data, to assess if the stability of performance is not due to coincidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa49910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = model(data_test).argmax(dim=1)\n",
    "nb_indivs_test = data_test.x.shape[0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct_test = (pred_test == data_test.y).sum()\n",
    "acc = int(correct_test) / nb_indivs_test\n",
    "print(f'Accuracy on test data: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad55b8b",
   "metadata": {},
   "source": [
    "# Visual Representation of the Graph\n",
    "Here, we will seek for a visual representation of the (directed acyclic?) graph. The goal is to check if it corresponds to the users' intuition - at least regarding the \"non sense\" causal paths. \n",
    "\n",
    "Here, the edges have been built with the directed path **sex -> education** (recall that the link [potentially] exists, because we voluntarily biased the data to be \"sexist\" regarding the distribution of incomes). Hence, the non-sense we don't want to find is an impact of education on sex. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "29cff6e8",
   "metadata": {},
   "source": [
    "# pip install --force-reinstall -v \"scipy==1.8\"\n",
    "!pip install --upgrade scipy networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78030ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6124b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_valid = to_networkx(data=data_valid)\n",
    "\n",
    "# subax1 = plt.subplot(121)\n",
    "\n",
    "# graph \n",
    "nx.draw(network_valid, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e96387",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_names = [\"occupation\", \"hours-per-week\"]#, \"sex\",\"education\"]\n",
    "\n",
    "data_job_valid = table_to_graph(X=X_valid, Y=Y_valid, list_col_names=list_col_names, edges=edges_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6fe68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a representation of the edge (\"sex -> education\") \n",
    "# with only 2 values of education and 20 individuals (min, max)\n",
    "\n",
    "X_valid.reset_index(drop=True, inplace=True)\n",
    "Y_valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_education_max = X_valid.loc[X_valid[\"education\"]==X_valid[\"education\"].max()].iloc[:10]\n",
    "#df_education_min = X_valid.loc[X_valid[\"education\"]==X_valid[\"education\"].min()].iloc[:10]\n",
    "\n",
    "X_education_extreme = df_education_max#.append(df_education_min).sort_index()\n",
    "Y_education_extreme = Y_valid.iloc[X_education_extreme.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, gain a representation with only 10 individuals \n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\", \"education\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid, with_labels=True, font_weight='bold')\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ad121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = [\"sex\"]\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=list_col_names)\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a13ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = ['capital-gain', 'capital-loss',\n",
    "       'hours-per-week', 'workclass', 'education', 'marital-status',\n",
    "       'occupation', 'relationship', 'race', 'sex', 'native-country',\n",
    "       'clients_id'] # to take only the likely 'relevant' features 'age', 'fnlwgt', 'education-num' as node\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=['sex'])\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, gain a representation with only 10 individuals (and only 'sex' as edge)\n",
    "\n",
    "t_graph_0 = time.time()\n",
    "\n",
    "list_col_names = ['age', 'fnlwgt', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week', 'workclass', 'education', 'marital-status',\n",
    "       'occupation', 'relationship', 'race', 'sex', 'native-country',\n",
    "       'clients_id'] # to take only the likely 'relevant' feature 'education-num' as node\n",
    "\n",
    "edges_sex_valid = add_new_edge(data=X_education_extreme, previous_edge=None, list_col_names=['sex'])\n",
    "\n",
    "data_sex_valid = table_to_graph(X=X_education_extreme, Y=Y_education_extreme, list_col_names=list_col_names, \n",
    "                                edges=edges_sex_valid)\n",
    "\n",
    "network_job_valid = to_networkx(data=data_job_valid)\n",
    "nx.draw(network_job_valid)\n",
    "\n",
    "t_graph_1 = time.time()\n",
    "\n",
    "print(f\"Plotting the graph with {data_sex_valid.x.shape[0]} individuals took {(t_graph_1 - t_graph_0)/60} mn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939edc4",
   "metadata": {},
   "source": [
    "Obviously, we have no clear intuition of what these links do correspond with... By individual, path from the sex to the income? But there are more groups than individuals here selected (10)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5823877",
   "metadata": {},
   "source": [
    "## Constitute a graph - Try to connect the features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76781366",
   "metadata": {},
   "source": [
    "Here, we proceed in 2 steps (back and forth)\n",
    "\n",
    "1. **Detect the relations**\n",
    "We use the partial dependance plots to inspect the correlations (pers) sufficient? Input intervention changes?\n",
    "\n",
    "1. **Select the causal direction**\n",
    "Based on the user's experience and expertise (e.g. sex -> education, because the contrary would be logically and temporally impossible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550aa49",
   "metadata": {},
   "source": [
    "At a first sight, look at correlated features (!) may be some hidden correlations => experience is still required at this stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstitute the dataset to check the correlations\n",
    "\n",
    "data_train_valid = X_train_valid.copy()\n",
    "data_train_valid['target'] = Y_train_valid\n",
    "data_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(data_train_valid.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c529c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)    \n",
    "g = sns.pairplot(X_train_valid.filter(items=['education-num','education']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(X_train_valid.filter(items=['sex','age']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8bbe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbb480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# detect the relations: show the changes in predictions for the combinations of 2 features\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "f_names = [('sex', 'education')]\n",
    "# Similar to previous PDP plot except we use tuple of features instead of single feature\n",
    "disp4 = PartialDependenceDisplay.from_estimator(model, X_valid, f_names, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
