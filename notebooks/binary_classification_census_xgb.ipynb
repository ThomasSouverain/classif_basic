{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Basic data preparation, modelling and analysis for binary classification (Census)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03693",
   "metadata": {},
   "source": [
    "## Train a model only with a statistical performance purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import time\n",
    "from sklearn import datasets\n",
    "\n",
    "from classif_basic.data_preparation import train_valid_test_split, set_target_if_feature, automatic_preprocessing\n",
    "from classif_basic.model import train_naive_xgb, pickle_save_model, prediction_train_valid_by_task, compute_best_fscore\n",
    "from classif_basic.model_analysis import features_importances_from_pickle, augment_train_valid_set_with_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107aa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your statistics purposes\n",
    "model_task = 'classification'\n",
    "stat_criteria = 'auc'\n",
    "\n",
    "# set how to pre-process the categorical features (one-hot encoding, or label-encoding)\n",
    "preprocessing_cat_features = \"label_encoding\"\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124240e",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "Fix precise % of population distribution (sex: Male, Female) and % of loan granted according to sex, to inspect the effects of FairDream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a741869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset on clients for binary classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target == '>50K') * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = X.copy()\n",
    "dataset['target'] = Y\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, \"treatment\" is saw as being 'Male' and not 'Female'\n",
    "\n",
    "df_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==1)]\n",
    "df_no_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==0)]\n",
    "df_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==1)]\n",
    "df_no_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==0)]\n",
    "\n",
    "print(df_response_if_feature.shape[0])\n",
    "print(df_no_response_if_feature.shape[0])\n",
    "print(df_response_if_not_feature.shape[0])\n",
    "print(df_no_response_if_not_feature.shape[0])\n",
    "\n",
    "\n",
    "# % of men selected by the initial data\n",
    "df_response_if_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of women selected by the initial data\n",
    "df_response_if_not_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_not_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dataset = 20_000\n",
    "\n",
    "percentage_feature= 70\n",
    "percentage_response_if_feature=70\n",
    "percentage_response_if_not_feature=10\n",
    "\n",
    "sexist_dataset = set_target_if_feature(\n",
    "    df_response_if_feature=df_response_if_feature,\n",
    "    df_no_response_if_feature=df_no_response_if_feature,\n",
    "    df_response_if_not_feature=df_response_if_not_feature,\n",
    "    df_no_response_if_not_feature=df_no_response_if_not_feature,\n",
    "    len_dataset=len_dataset,\n",
    "    percentage_feature=percentage_feature,\n",
    "    percentage_response_if_feature=percentage_response_if_feature,\n",
    "    percentage_response_if_not_feature=percentage_response_if_not_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sexist_dataset.loc[: , dataset.columns != 'target']\n",
    "Y = sexist_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d78af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb9644",
   "metadata": {},
   "source": [
    "### Bring your own model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a8be6",
   "metadata": {},
   "source": [
    "If you want to bring your own model, you have to set 3 features:\n",
    "\n",
    "1. uncorrected_model_path\n",
    "Save your model in uncorrected_model_path, for fairness analysis on relevant features\n",
    "Ex: uncorrected_model_path = \"/work/data/models/uncorrected_model.pkl\"\n",
    "\n",
    "2. X_train_valid, Y_train_valid\n",
    "pd.DataFrame with your inputs and targets on train&valid set, of shape(nb_individuals,)\n",
    "\n",
    "3. Y_pred_train_valid\n",
    "np.ndarray with the predicted label (i.e. class) or value, of shape(nb_individuals,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447f8c",
   "metadata": {},
   "source": [
    "### Automatically train a model statistically performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e01c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_train_valid, X_test, Y_train, Y_valid, Y_train_valid, Y_test = train_valid_test_split(\n",
    "    X=X,\n",
    "    Y=Y, \n",
    "    model_task=model_task,\n",
    "    preprocessing_cat_features=preprocessing_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e26fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438539df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the uncorrected model, to then sort its features by importances\n",
    "save_model=True\n",
    "uncorrected_model_path = \"/work/data/models/uncorrected_model.pkl\"\n",
    "\n",
    "Y_pred_train_valid = train_naive_xgb(\n",
    "    X_train=X_train,\n",
    "    X_valid=X_valid,\n",
    "    X_train_valid=X_train_valid,\n",
    "    X_test=X_test,\n",
    "    Y_train=Y_train,\n",
    "    Y_valid=Y_valid,\n",
    "    Y_train_valid=Y_train_valid,\n",
    "    Y_test=Y_test,\n",
    "    model_task=model_task,\n",
    "    stat_criteria=stat_criteria,\n",
    "    save_model=save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b5cd3",
   "metadata": {},
   "source": [
    "### Basic analysis of the model: DataFrame with the results, Feature Importance from Shapley values (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32837850",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_valid_set = augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e3a0f",
   "metadata": {},
   "source": [
    "We now see that this process with basic data preparation, modelling and integration of the results in a DataFrame (as storage of the model) is very fast (in seconds):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebefe615",
   "metadata": {},
   "source": [
    "features_importances_from_pickle(\n",
    "    augmented_train_valid_set=augmented_train_valid_set,\n",
    "    X_train_valid=X_train_valid,\n",
    "    model_task=model_task,\n",
    "    uncorrected_model_path=uncorrected_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "print(f\"Basic modelling took {round(t1 - t0)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c6a49",
   "metadata": {},
   "source": [
    "The further steps are for fairness assessment and correction of the model, functionality which is available with the package FairDream of DreamQuark (private for the moment)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48be396",
   "metadata": {},
   "source": [
    "## Detection alert (on train&valid data to examine if the model learned discriminant behavior)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4108de8c",
   "metadata": {},
   "source": [
    "augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddfaf680",
   "metadata": {},
   "source": [
    "train_valid_set_with_uncorrected_results = augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1da81ac9",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "augmented_train_valid_set = train_valid_set_with_uncorrected_results\n",
    "model_name = \"uncorrected\"\n",
    "\n",
    "fairness_purpose='percentage_positive'\n",
    "injustice_acceptance=1\n",
    "min_individuals_discrimined=0.01\n",
    "\n",
    "discrimination_alert(augmented_train_valid_set, model_name, fairness_purpose, model_task, injustice_acceptance, min_individuals_discrimined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6fb59",
   "metadata": {},
   "source": [
    "## Discrimination correction with a new fair model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbadc17",
   "metadata": {},
   "source": [
    "### Generating fairer models with grid search or weights distorsion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5e1dad5",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# the user determines one's fairness objectives to build new fairer models\n",
    "# on which group and regarding which criteria (purpose, constraint of the models) one aims to erase discrimination\n",
    "\n",
    "protected_attribute = 'education-num'\n",
    "\n",
    "# then the user sets the desired balance between stat and fair performances \n",
    "tradeoff = \"moderate\"\n",
    "weight_method = 'grid_and_weighted_groups'\n",
    "nb_fair_models = 6\n",
    "\n",
    "\n",
    "train_valid_set_with_corrected_results, models_df, best_model_dict = fair_train(\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    train_valid_set_with_uncorrected_results=train_valid_set_with_uncorrected_results,\n",
    "    protected_attribute=protected_attribute,\n",
    "    fairness_purpose=fairness_purpose,\n",
    "    model_task=model_task,\n",
    "    stat_criteria=stat_criteria,\n",
    "    tradeoff=tradeoff,\n",
    "    weight_method=weight_method,\n",
    "    nb_fair_models=nb_fair_models,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35c752",
   "metadata": {},
   "source": [
    "### Evaluating the best fair model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39cd5d2d",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fair_model_results(train_valid_set_with_corrected_results, models_df, best_model_dict,protected_attribute,fairness_purpose, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef3cfd4f",
   "metadata": {},
   "source": [
    "top_models = models_df.sort_values(by='tradeoff_score',ascending=False)\n",
    "top_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
