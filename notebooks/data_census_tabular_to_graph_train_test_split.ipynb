{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2affb517",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "In this notebook, we inspect **in which way a tabular dataset as Census can be used by an AI based on graphs to estimate wealthiness of individuals**. \n",
    "\n",
    "Therefore, we proceed in 2 steps:\n",
    "\n",
    "**1. We prepare data to be handled by a model based on a graph**\n",
    "We transform them into a graph, that involves strong assumptions on the features involved in connections...\n",
    "\n",
    "**2. We train an AI based on graphs**\n",
    "Here, we begin with a Graphical Neural Network (GNN) based on a Multi-Layer Perceptron (MLP), requiring the library Torch.\n",
    "\n",
    "**3. We inspect if the graph-based AI indeed reflects common & expert knowledge on**\n",
    "In particular, regarding the non-sense of certain inferences that should absolutely be avoided (e.g. education may influence occupation, but not the reverse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5582cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Data preparation for binary classification with graphs (Census)\n",
    "For this reshaping (and also interpretation, see below the choice of edges) of data tables to graphs, we based on https://colab.research.google.com/drive/1_eR7DXBF3V4EwH946dDPOxeclDBeKNMD?usp=sharing#scrollTo=WuggdIItffpv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03693",
   "metadata": {},
   "source": [
    "## General preparation - handle categorical features\n",
    "Here, we handle the categorical features through label-encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bad479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import time\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from classif_basic.data_preparation import train_valid_test_split, set_target_if_feature, automatic_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124240e",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "Fix precise % of population distribution (sex: Male, Female) and % of wealthiness according to sex. In that way, we could inspect if the structure of the model (here based on a graph) integrates this \"sexist\" representation of the world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a741869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset on clients for binary classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target == '>50K') * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb5911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     workclass    fnlwgt     education  education-num  \\\n",
       "0      25.0       Private  226802.0          11th            7.0   \n",
       "1      38.0       Private   89814.0       HS-grad            9.0   \n",
       "2      28.0     Local-gov  336951.0    Assoc-acdm           12.0   \n",
       "3      44.0       Private  160323.0  Some-college           10.0   \n",
       "4      18.0           NaN  103497.0  Some-college           10.0   \n",
       "...     ...           ...       ...           ...            ...   \n",
       "48837  27.0       Private  257302.0    Assoc-acdm           12.0   \n",
       "48838  40.0       Private  154374.0       HS-grad            9.0   \n",
       "48839  58.0       Private  151910.0       HS-grad            9.0   \n",
       "48840  22.0       Private  201490.0       HS-grad            9.0   \n",
       "48841  52.0  Self-emp-inc  287927.0       HS-grad            9.0   \n",
       "\n",
       "           marital-status         occupation relationship   race     sex  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                NaN    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  target  \n",
       "0               0.0           0.0            40.0  United-States       0  \n",
       "1               0.0           0.0            50.0  United-States       0  \n",
       "2               0.0           0.0            40.0  United-States       1  \n",
       "3            7688.0           0.0            40.0  United-States       1  \n",
       "4               0.0           0.0            30.0  United-States       0  \n",
       "...             ...           ...             ...            ...     ...  \n",
       "48837           0.0           0.0            38.0  United-States       0  \n",
       "48838           0.0           0.0            40.0  United-States       1  \n",
       "48839           0.0           0.0            40.0  United-States       0  \n",
       "48840           0.0           0.0            20.0  United-States       0  \n",
       "48841       15024.0           0.0            40.0  United-States       1  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = X.copy()\n",
    "dataset['target'] = Y\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ccb74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9918\n",
      "22732\n",
      "1769\n",
      "14423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3037672281776417"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here, \"treatment\" is saw as being 'Male' and not 'Female'\n",
    "\n",
    "df_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==1)]\n",
    "df_no_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==0)]\n",
    "df_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==1)]\n",
    "df_no_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==0)]\n",
    "\n",
    "print(df_response_if_feature.shape[0])\n",
    "print(df_no_response_if_feature.shape[0])\n",
    "print(df_response_if_not_feature.shape[0])\n",
    "print(df_no_response_if_not_feature.shape[0])\n",
    "\n",
    "\n",
    "# % of men selected by the initial data\n",
    "df_response_if_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f3d21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07267573230352081"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of women selected by the initial data\n",
    "df_response_if_not_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_not_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1cbf2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_dataset: 20000\n",
      "nb indivs feature with response: 9800\n",
      "nb indivs feature with no response: 4200\n",
      "nb indivs not_feature with response: 600\n",
      "nb indivs not_feature with no response: 5400\n"
     ]
    }
   ],
   "source": [
    "len_dataset = 20_000\n",
    "\n",
    "percentage_feature= 70\n",
    "percentage_response_if_feature=70\n",
    "percentage_response_if_not_feature=10\n",
    "\n",
    "sexist_dataset = set_target_if_feature(\n",
    "    df_response_if_feature=df_response_if_feature,\n",
    "    df_no_response_if_feature=df_no_response_if_feature,\n",
    "    df_response_if_not_feature=df_response_if_not_feature,\n",
    "    df_no_response_if_not_feature=df_no_response_if_not_feature,\n",
    "    len_dataset=len_dataset,\n",
    "    percentage_feature=percentage_feature,\n",
    "    percentage_response_if_feature=percentage_response_if_feature,\n",
    "    percentage_response_if_not_feature=percentage_response_if_not_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb3a0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sexist_dataset.loc[: , dataset.columns != 'target']\n",
    "Y = sexist_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d78af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24648    1\n",
       "12622    1\n",
       "18850    1\n",
       "18242    1\n",
       "21556    1\n",
       "        ..\n",
       "5584     0\n",
       "3186     0\n",
       "38137    0\n",
       "42540    0\n",
       "9717     0\n",
       "Name: target, Length: 20000, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447f8c",
   "metadata": {},
   "source": [
    "### Train-test-split, to prepare for 3 graphs representing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e01c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task = \"classification\"\n",
    "preprocessing_cat_features = \"label_encoding\"\n",
    "\n",
    "X_train, X_valid, X_train_valid, X_test, Y_train, Y_valid, Y_train_valid, Y_test = train_valid_test_split(\n",
    "    X=X,\n",
    "    Y=Y, \n",
    "    model_task=model_task,\n",
    "    preprocessing_cat_features=preprocessing_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99abfa",
   "metadata": {},
   "source": [
    "## Reshape (by interpreting) data to a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756db59",
   "metadata": {},
   "source": [
    "From this dataset (where we introduced selectively a \"sexist\" effect against women), let's see how we could swith from the tabular data to a graph representation.\n",
    "\n",
    "The point is that our features X all seem to be attributes of the clients, though we should find a way of representing their interactions between clients \n",
    "\n",
    "X = {race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, occupation, hours per week, workclass, race, sex, capital gain, capital loss, native country} \n",
    "\n",
    "**Nodes** \n",
    "Bank clients (by ID)\n",
    "\n",
    "**Edges** \n",
    "Here, we should find one or several ways of connecting the clients\n",
    "\n",
    "Should be occupation → if changes of occupation (or similar client with new occupation), which impact on the revenue? // change of football team => impact on the football rate \n",
    "(pers) actionable => predict revenue when switches to a new job??\n",
    "→ may be: “hours per week” <=> inspect the change of revenue if switches to greater hours per week?\n",
    "\n",
    "**Node Features** \n",
    "Attributs of the nodes, i.e. characteristics of the clients (here, hard to separate from what \"connects\" them...) \n",
    "\n",
    "Race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, hours per week, workclass, race, sex, capital gain, capital loss, native country \n",
    "\n",
    "**Label (here at a node-level?)** \n",
    "Income (Y = income > $50 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04dc31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all, specify the edge\n",
    "edge = \"occupation\"# str (for the moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "403774e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: 'Prof-specialty',\n",
       " 3: 'Exec-managerial',\n",
       " 11: 'Sales',\n",
       " 2: 'Craft-repair',\n",
       " 10: 'Protective-serv',\n",
       " 0: 'Adm-clerical',\n",
       " 14: 'Transport-moving',\n",
       " 6: 'Machine-op-inspct',\n",
       " 12: 'Tech-support',\n",
       " 13: 'Transport-moving',\n",
       " 4: 'Farming-fishing',\n",
       " 7: 'Other-service',\n",
       " 5: 'Handlers-cleaners',\n",
       " 1: 'Armed-Forces',\n",
       " 8: 'Priv-house-serv'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an idea of the codes corresponding to occupations, reconstituting labels' transformations from X\n",
    "le = LabelEncoder()\n",
    "\n",
    "dict_occupation_codes = pd.Series(X[edge].values, index=X.apply(le.fit_transform)[edge]).to_dict()\n",
    "\n",
    "# correct according to dict comparison\n",
    "dict_occupation_codes[14] = 'Transport-moving'\n",
    "dict_occupation_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0102966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO enhance the function (and then include it in the package)\n",
    "\n",
    "def table_to_graph(X, Y, edge):\n",
    "    \n",
    "    #Make sure that we have no duplicate nodes\n",
    "    assert(X.index.unique().shape[0] == X.shape[0])\n",
    "    \n",
    "    # first of all, reset the IDs of clients\n",
    "    X[\"clients_id\"] = X.reset_index().index\n",
    "    \n",
    "    # Extract the node features\n",
    "\n",
    "        # The node features are typically represented in a matrix of the shape (num_nodes, node_feature_dim).\n",
    "        # For each of the bank clients, we simply extract their attributes (except here the \"occupation\", that would be used as an \"actionable\" edge to connect them)\n",
    "    node_features = X.loc[:, X.columns != edge]\n",
    "        # That's already our node feature matrix. The number of nodes and the ordering is implicitly defined by it's shape. Each row corresponds to one node in our final graph. \n",
    "    \n",
    "    # Convert to numpy\n",
    "    x = node_features.to_numpy()\n",
    "    # x.shape # [num_nodes x num_features]\n",
    "    # then convert to torch, for further compatibility avec the torch GNN\n",
    "    x = torch.from_numpy(x)\n",
    "    \n",
    "    # Extract the labels\n",
    "    labels = Y\n",
    "        # Those are simply the wealthiness of each of the clients (if their income is >$50 000). This corresponds to a node-level prediction problem. \n",
    "        # Therefore we have as many labels as we have nodes.\n",
    "    \n",
    "    # to make the graph functioning, check that the nodes follow the same order than the labels (rows n°)\n",
    "        # else, sort values by ids\n",
    "    nb_corresponding_nodes_labels = (labels.index == node_features.index).sum()\n",
    "    assert(nb_corresponding_nodes_labels == X.shape[0])\n",
    "    \n",
    "    # Convert to numpy\n",
    "    y = labels.to_numpy()\n",
    "    #y.shape # [num_nodes, 1] --> node regression\n",
    "    # get the number of classes\n",
    "    num_classes=np.unique(y).shape[0]\n",
    "    # then convert to torch, for further compatibility avec the torch GNN\n",
    "    y = torch.from_numpy(y)\n",
    "\n",
    "    # Extract the edges\n",
    "        # That's probably the trickiest part with a tabular dataset. You need to think of a reasonable way to connect your nodes. \n",
    "        # We will use the type of job assignment here\n",
    "        # We now need to build all permutations of these clients within one type of job, which corresponds to a fully-connected graph within each occupation-subgroup. We use the column int_player_id as indices for the edges. If there is for example a [0, 1] in the edge index, it means that the first and second node (regarding the previously defined node feature matrix) are connected.\n",
    "    \n",
    "    jobs = X[\"occupation\"].unique()\n",
    "    all_edges = np.array([], dtype=np.int32).reshape((0, 2))\n",
    "    for job in jobs:\n",
    "        job_df = X[X[\"occupation\"] == job]\n",
    "        clients = job_df[\"clients_id\"].values        # Build all combinations, as all players are connected\n",
    "        permutations = list(itertools.combinations(clients, 2))\n",
    "        edges_source = [e[0] for e in permutations]\n",
    "        edges_target = [e[1] for e in permutations]\n",
    "        clients_edges = np.column_stack([edges_source, edges_target])\n",
    "        all_edges = np.vstack([all_edges, clients_edges])\n",
    "        \n",
    "    # begin with empty edge_index, to assess if the GNN structure works\n",
    "    #edge_index = torch.empty(2, 0, dtype=torch.long)\n",
    "        \n",
    "    # Convert to Pytorch Geometric format\n",
    "    edge_index = all_edges.transpose()\n",
    "    # edge_index # [2, num_edges]\n",
    "    # then convert to torch, for further compatibility avec the torch GNN\n",
    "    edge_index = torch.from_numpy(edge_index)\n",
    "    \n",
    "    # finally, build the graph (if other attributes e.g. edge_features, you can also pass it there)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y, num_classes=num_classes)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a959c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = table_to_graph(X=X_train, Y=Y_train, edge=edge)\n",
    "data_valid = table_to_graph(X=X_valid, Y=Y_valid, edge=edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4bfed66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[14450, 14], edge_index=[2, 11537004], y=[14450], num_classes=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54040b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2550, 14], edge_index=[2, 372392], y=[2550], num_classes=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b5cd3",
   "metadata": {},
   "source": [
    "# Train a basic Graph Neural Network on the graph-shaped data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32385c",
   "metadata": {},
   "source": [
    "## Build a basic convolutional GNN with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5ede7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here intervenes the quick \"introduction by example\" of GCN by torch\n",
    "# in 'https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html'\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, data.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "767f6f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(data=data_train).to(device)\n",
    "data_train = data_train.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.double()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 201):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data_train)\n",
    "    loss = F.nll_loss(out, data_train.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed9109d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-19623.5733,      0.0000],\n",
       "        [     0.0000, -57809.4922],\n",
       "        [ -3619.6687,      0.0000],\n",
       "        ...,\n",
       "        [ -1045.5856,      0.0000],\n",
       "        [     0.0000,  -2905.7014],\n",
       "        [ -8054.6182,      0.0000]], dtype=torch.float64,\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d174f7",
   "metadata": {},
   "source": [
    "Finally, we can evaluate our model on the validation nodes. Obviously, linking the clients only through the job provides less than 70% of accuracy even on the train set. Therefore, we need to seek for other ways..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57509b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data: 0.6482\n"
     ]
    }
   ],
   "source": [
    "pred_train = model(data_train).argmax(dim=1)\n",
    "nb_indivs_train = data_train.x.shape[0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct_train = (pred_train == data_train.y).sum()\n",
    "acc = int(correct_train) / nb_indivs_train\n",
    "print(f'Accuracy on train data: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd7693ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5255\n"
     ]
    }
   ],
   "source": [
    "pred_valid = model(data_valid).argmax(dim=1)\n",
    "nb_indivs_valid = data_valid.x.shape[0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct_valid = (pred_valid == data_valid.y).sum()\n",
    "acc = int(correct_valid) / nb_indivs_valid\n",
    "print(f'Accuracy on test data: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67c05d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  27,   41,   56,  ..., 7833, 9610, 9610])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connections of the node 1 with the other (14450-1) nodes\n",
    "# obviously there is a problem, as the node 18460 does not exist...\n",
    "data_train.edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd2a3fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 6111, 6111, 7833],\n",
       "        [  27,   41,   56,  ..., 7833, 9610, 9610]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442bd73",
   "metadata": {},
   "source": [
    "## Build the GNN with torch\n",
    "The advantage of using torch_geometric to build the GNN is the compatibility with the graph of data, as data was just reshaped using torch_geometric (above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch_geometric.nn import Sequential, GCNConv, JumpingKnowledge\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "num_data_classes = 2\n",
    "\n",
    "model = Sequential('x, edge_index, batch', [\n",
    "    (Dropout(p=0.5), 'x -> x'),\n",
    "    (GCNConv(data_train.num_features, 64), 'x, edge_index -> x1'),\n",
    "    ReLU(inplace=True),\n",
    "    (GCNConv(64, 64), 'x1, edge_index -> x2'),\n",
    "    ReLU(inplace=True),\n",
    "    (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n",
    "    (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n",
    "    (global_mean_pool, 'x, batch -> x'),\n",
    "    Linear(2 * 64, num_data_classes),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b198c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_train.x\n",
    "edge_index = data_train.edge_index\n",
    "batch = 10\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703ac06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "x = data_train.x\n",
    "edge_index = data_train.edge_index\n",
    "batch = 10\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = data_train.x\n",
    "    edge_index = data_train.edge_index\n",
    "    batch = 10\n",
    "    \n",
    "    out = model(x, edge_index, batch)\n",
    "    loss = F.nll_loss(data_train, data_train.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e1278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = data_valid.x\n",
    "edge_index = data_valid.edge_index\n",
    "batch = 10\n",
    "\n",
    "pred_valid = model().argmax(dim=1)\n",
    "nb_indivs_valid = data_valid.x.shape[0]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = (pred_valid == data_valid).sum()\n",
    "acc = int(correct) / nb_indivs_valid\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328acf0",
   "metadata": {},
   "source": [
    "## Training a Graph Neural Network (GNN)\n",
    "\n",
    "We can easily convert our MLP to a GNN by swapping the `torch.nn.Linear` layers with PyG's GNN operators.\n",
    "\n",
    "Following-up on [the first part of the Torch tutorial we used](https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8), we replace the linear layers by the [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) module.\n",
    "To recap, the **GCN layer** ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)) is defined as\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{W}^{(\\ell + 1)}$ denotes a trainable weight matrix of shape `[num_output_features, num_input_features]` and $c_{w,v}$ refers to a fixed normalization coefficient for each edge.\n",
    "In contrast, a single `Linear` layer is defined as\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\mathbf{x}_v^{(\\ell)}\n",
    "$$\n",
    "\n",
    "which does not make use of neighboring node information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d30e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                     node_color=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb985e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data_train  # Get the first graph object.\n",
    "\n",
    "print(data)\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "#print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "#print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "#print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "# print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38b7c9",
   "metadata": {},
   "source": [
    "By printing edge_index, we can understand how PyG represents graph connectivity internally. We can see that for each edge, edge_index holds a tuple of two node indices, where the first value describes the node index of the source node and the second value describes the node index of the destination node of an edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "edge_index = data.edge_index\n",
    "print(edge_index.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e916c",
   "metadata": {},
   "source": [
    "We can further visualize the graph by converting it to the networkx library format, which implements, in addition to graph manipulation functionalities, powerful tools for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67674d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "G = to_networkx(tf.convert_to_tensor(data), to_undirected=True)\n",
    "visualize_graph(G, color=tf.convert_to_tensor(data.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7fbba",
   "metadata": {},
   "source": [
    "Here, there was the code of yesterday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(data_train.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 2) # number of classes on the data\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f0f05",
   "metadata": {},
   "source": [
    "**Embedding the Census Network**\n",
    "\n",
    "Let's take a look at the node embeddings produced by our GNN.\n",
    "Here, we pass in the initial node features `x` and the graph connectivity information `edge_index` to the model, and visualize its 2-dimensional embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, h = model(data_train.x, data_train.edge_index)\n",
    "print(f'Embedding shape: {list(h.shape)}')\n",
    "\n",
    "visualize_embedding(h, color=data_train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5f944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40841772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data_train.x, data_train.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out, data_train.y)  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data_valid.x, data_valid.edge_index)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred == data_test.y  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(data_test.sum())  # Derive ratio of correct predictions.\n",
    "    return test_acc\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32837850",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_valid_set = augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e3a0f",
   "metadata": {},
   "source": [
    "We now see that this process with basic data preparation, modelling and integration of the results in a DataFrame (as storage of the model) is very fast (in seconds):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebefe615",
   "metadata": {},
   "source": [
    "features_importances_from_pickle(\n",
    "    augmented_train_valid_set=augmented_train_valid_set,\n",
    "    X_train_valid=X_train_valid,\n",
    "    model_task=model_task,\n",
    "    uncorrected_model_path=uncorrected_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "print(f\"Basic modelling took {round(t1 - t0)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c6a49",
   "metadata": {},
   "source": [
    "The further steps are for fairness assessment and correction of the model, functionality which is available with the package FairDream of DreamQuark (private for the moment)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48be396",
   "metadata": {},
   "source": [
    "## Detection alert (on train&valid data to examine if the model learned discriminant behavior)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4108de8c",
   "metadata": {},
   "source": [
    "augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddfaf680",
   "metadata": {},
   "source": [
    "train_valid_set_with_uncorrected_results = augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1da81ac9",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "augmented_train_valid_set = train_valid_set_with_uncorrected_results\n",
    "model_name = \"uncorrected\"\n",
    "\n",
    "fairness_purpose='percentage_positive'\n",
    "injustice_acceptance=1\n",
    "min_individuals_discrimined=0.01\n",
    "\n",
    "discrimination_alert(augmented_train_valid_set, model_name, fairness_purpose, model_task, injustice_acceptance, min_individuals_discrimined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6fb59",
   "metadata": {},
   "source": [
    "## Discrimination correction with a new fair model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbadc17",
   "metadata": {},
   "source": [
    "### Generating fairer models with grid search or weights distorsion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5e1dad5",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# the user determines one's fairness objectives to build new fairer models\n",
    "# on which group and regarding which criteria (purpose, constraint of the models) one aims to erase discrimination\n",
    "\n",
    "protected_attribute = 'education-num'\n",
    "\n",
    "# then the user sets the desired balance between stat and fair performances \n",
    "tradeoff = \"moderate\"\n",
    "weight_method = 'grid_and_weighted_groups'\n",
    "nb_fair_models = 6\n",
    "\n",
    "\n",
    "train_valid_set_with_corrected_results, models_df, best_model_dict = fair_train(\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    train_valid_set_with_uncorrected_results=train_valid_set_with_uncorrected_results,\n",
    "    protected_attribute=protected_attribute,\n",
    "    fairness_purpose=fairness_purpose,\n",
    "    model_task=model_task,\n",
    "    stat_criteria=stat_criteria,\n",
    "    tradeoff=tradeoff,\n",
    "    weight_method=weight_method,\n",
    "    nb_fair_models=nb_fair_models,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35c752",
   "metadata": {},
   "source": [
    "### Evaluating the best fair model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39cd5d2d",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fair_model_results(train_valid_set_with_corrected_results, models_df, best_model_dict,protected_attribute,fairness_purpose, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef3cfd4f",
   "metadata": {},
   "source": [
    "top_models = models_df.sort_values(by='tradeoff_score',ascending=False)\n",
    "top_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
