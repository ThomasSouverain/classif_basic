{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc841c5f",
   "metadata": {},
   "source": [
    "## Enforcing causal paths in tabular GNN - Full data-graph (x, edge_index) child knowledge\n",
    "\n",
    "To train a GNN while respecting a minimal set of causal paths, we pass to the GNN 2 types of graph-data:\n",
    "- ancestor: with only the ancestor nodes\n",
    "- child: ancestor + child nodes, adding as an edge \"ancestor -> child\"\n",
    "\n",
    "-> s.t. child(n) becomes the ancestor of child(n+1)\n",
    "\n",
    "Constitute 2 graph-data parent/child, suggesting causality by adding child nodes (and also edge: parent -> child) in the child data.\n",
    "\n",
    "For the moment, we specify only 1 parent per edge, on 2 layers:\n",
    "- ancestor layer: age -> occupation\n",
    "- child layer: occupation -> hours of work per week\n",
    "\n",
    "For the moment, to avoid spurious correlations we also keep only the ancestor features (age, sex, race, native country) as node features for all graph-data. Based on this ancestor \"blind knowledge\", add the child as node features (and also edge: parent -> child) in the child graph-data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc5f3b",
   "metadata": {},
   "source": [
    "Causal analysis: before train&valid/test split, we reduced the number of features to contain only \"straightforward\" causal information -> enabling to integrate it progressively in our GNN (through edges). Therefore, we use factor analysis:\n",
    "\n",
    "To control for the balance of df across classes, we sort the clients so that X gets perfect equality in the repartition of classes 0 and 1 (at the cost of 25 000 instead of the 45 000 initial individuals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19753f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports and train/test split (to be put in part 2. of the notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "try:\n",
    "    import torch_geometric\n",
    "except ModuleNotFoundError:\n",
    "    TORCH = torch.__version__.split(\"+\")[0]\n",
    "    CUDA = \"cu\" + torch.version.cuda.replace(\".\",\"\")\n",
    "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "#!pip install torch-geometric\n",
    "#import torch_geometric\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from classif_basic.data_preparation import handle_cat_features\n",
    "\n",
    "from classif_basic.graph.train import train_xgb_benchmark, get_auc\n",
    "\n",
    "from classif_basic.model import pickle_load_model, pickle_save_model\n",
    "\n",
    "# preparing the dataset on clients for binary classification\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target == '>50K') * 1\n",
    "\n",
    "SEED = 7\n",
    "VALID_SIZE = 0.15\n",
    "preprocessing_cat_features = \"label_encoding\"\n",
    "\n",
    "X = handle_cat_features(X=X, preprocessing_cat_features=preprocessing_cat_features)\n",
    "\n",
    "# first of all, unify features with \"redundant\" causal information\n",
    "from classif_basic.graph.utils import get_unified_col\n",
    "\n",
    "X = get_unified_col(X=X, list_cols_to_join = [\"education\",\"education-num\"], new_col_name = \"education\")\n",
    "X = get_unified_col(X=X, list_cols_to_join = [\"relationship\",\"marital-status\"], new_col_name = \"relationship\")\n",
    "X = get_unified_col(X=X, list_cols_to_join = [\"occupation\",\"workclass\"], new_col_name = \"job\")\n",
    "X = get_unified_col(X=X, list_cols_to_join = [\"capital-gain\",\"capital-loss\"], new_col_name = \"capital\")\n",
    "\n",
    "# select equal proportion of classes \"wealthy\" and \"not wealthy\", and generates the new dataset accordingly\n",
    "from classif_basic.graph.utils import get_balanced_df\n",
    "\n",
    "balanced_df = get_balanced_df(X=X, Y=Y)\n",
    "\n",
    "X_balanced = balanced_df.drop(\"target\", axis=1)\n",
    "Y_balanced = balanced_df[\"target\"]\n",
    "\n",
    "X=X_balanced # here, we try with the whole dataset (assuming it is imbalanced, but counts almost 50 000 nodes)\n",
    "Y=Y_balanced\n",
    "\n",
    "# then, normalize the df categories for better neural-network computation\n",
    "from classif_basic.graph.utils import normalize_df\n",
    "\n",
    "X=normalize_df(df=X, normalization='min_max')\n",
    "\n",
    "# Split valid set for early stopping & model selection\n",
    "# \"stratify=Y\" to keep the same proportion of target classes in train/valid (i.e. model) and test sets \n",
    "X_model, X_test, Y_model, Y_test = train_test_split(\n",
    "    X, Y, test_size=VALID_SIZE, random_state=SEED, stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57745ece",
   "metadata": {},
   "source": [
    "# Load and test previous models (plot AUCs...)\n",
    "We here load our basic GCN, trained on 20 000 epochs (around 100/120 mn):\n",
    "- the \"classic\" - correlated, with all columns as feature nodes and only one edge\n",
    "- the \"test\", with layers integrating successive causal edges (2 edges for the moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fcebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from classif_basic.graph.train import activate_gpu   \n",
    "\n",
    "gcn_classic = pickle_load_model(\"/work/data/models/gcn_classic_education_relationship.pkl\")\n",
    "gcn_ancestor = pickle_load_model(\"/work/data/models/gcn_ancestor_education_relationship_job.pkl\")\n",
    "\n",
    "dict_data_total = pickle_load_model(\"/work/data/graph_data/balanced/dict_all_edges.pkl\")\n",
    "\n",
    "data_full_education_relationship = pickle_load_model(\"/work/data/graph_data/balanced/data_full_features_education_relationship.pkl\")\n",
    "\n",
    "device = activate_gpu()\n",
    "\n",
    "preds_classic = gcn_classic(list_data=[data_full_education_relationship], device=device, skip_connection=True)\n",
    "\n",
    "preds_ancestor = gcn_ancestor(\n",
    "    list_data=[dict_data_total['education->relationship'],\n",
    "                                 dict_data_total['relationship->job']],\n",
    "    device=device, \n",
    "    skip_connection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6695d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after loading the models, save their predictions\n",
    "pickle_save_model(preds_classic, \"/work/data/graph_data/balanced/edge_ed_rel_job.preds_classic.pkl\")\n",
    "\n",
    "pickle_save_model(preds_ancestor, \"/work/data/graph_data/balanced/edge_ed_rel_job.preds_ancestor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad07d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and plot AUCs...\n",
    "# get y to plot AUC\n",
    "for edge_name, graph_data in dict_data_total.items():\n",
    "    y_true=graph_data.y\n",
    "\n",
    "plot = True\n",
    "\n",
    "# first, plot AUCs for the classic GNN (with full features as node features)\n",
    "# the printed scores are respectively ROC AUC, PR AUC, False Positive and True Positive Ratios\n",
    "print(\"AUCs for the classic GNN (with full features as node features)\")\n",
    "get_auc(y_true=y_true, probas_pred=preds_classic, plot=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, plot AUCs for the ancestor GNN (with 2 progressive layers of edges, education -> relationship -> job)\n",
    "print(\"AUCs for the ancestor GNN (with 2 progressive layers of edges, education -> relationship -> job)\")\n",
    "get_auc(y_true=y_true, probas_pred=preds_ancestor, plot=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to reallocate GPU memory, at the end!\n",
    "del preds_classic\n",
    "del preds_ancestor\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8c380",
   "metadata": {},
   "source": [
    "# Basic XGB for comparison - excellent results\n",
    "With the same unified features 92% ROC-AUC, 81-84% PR-AUC, 85% accuracy on train&valid sets.\n",
    "\n",
    "**Conclusion** between at least **10-18% less than optimized XGB on all metrics** - respectable for non-optimized structures (basic edges, , basic GCN), our GNN (causal as non causal) have to be optimized..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classif_basic.graph.train import train_xgb_benchmark\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
    "    X_model, Y_model, test_size=VALID_SIZE, random_state=SEED, stratify=Y_model\n",
    ")\n",
    "\n",
    "train_xgb_benchmark(X_train=X_train, X_valid=X_valid, Y_train=Y_train, Y_valid=Y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
