{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58dd94",
   "metadata": {},
   "source": [
    "# Basic data preparation, modelling and analysis for binary classification (Census)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab03693",
   "metadata": {},
   "source": [
    "## Train a model only with a statistical performance purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe4260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb38c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import time\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from classif_basic.data_preparation import train_valid_test_split, set_target_if_feature, automatic_preprocessing\n",
    "from classif_basic.model import train_naive_xgb, pickle_save_model, prediction_train_valid_by_task, compute_best_fscore\n",
    "from classif_basic.model_analysis import features_importances_from_pickle, augment_train_valid_set_with_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107aa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your statistics purposes\n",
    "model_task = 'classification'\n",
    "stat_criteria = 'auc'\n",
    "\n",
    "# set how to pre-process the categorical features (one-hot encoding, or label-encoding)\n",
    "preprocessing_cat_features = \"label_encoding\"\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124240e",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "Fix precise % of population distribution (sex: Male, Female) and % of loan granted according to sex, to inspect the effects of FairDream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a741869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the dataset on clients for binary classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "Y = (data.target == '>50K') * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = X.copy()\n",
    "dataset['target'] = Y\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, \"treatment\" is saw as being 'Male' and not 'Female'\n",
    "\n",
    "df_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==1)]\n",
    "df_no_response_if_feature=dataset.loc[(dataset['sex']=='Male')&(dataset['target']==0)]\n",
    "df_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==1)]\n",
    "df_no_response_if_not_feature=dataset.loc[(dataset['sex']=='Female')&(dataset['target']==0)]\n",
    "\n",
    "print(df_response_if_feature.shape[0])\n",
    "print(df_no_response_if_feature.shape[0])\n",
    "print(df_response_if_not_feature.shape[0])\n",
    "print(df_no_response_if_not_feature.shape[0])\n",
    "\n",
    "\n",
    "# % of men selected by the initial data\n",
    "df_response_if_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of women selected by the initial data\n",
    "df_response_if_not_feature.shape[0]/(df_response_if_feature.shape[0]+df_no_response_if_not_feature.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dataset = 20_000\n",
    "\n",
    "percentage_feature= 70\n",
    "percentage_response_if_feature=70\n",
    "percentage_response_if_not_feature=10\n",
    "\n",
    "sexist_dataset = set_target_if_feature(\n",
    "    df_response_if_feature=df_response_if_feature,\n",
    "    df_no_response_if_feature=df_no_response_if_feature,\n",
    "    df_response_if_not_feature=df_response_if_not_feature,\n",
    "    df_no_response_if_not_feature=df_no_response_if_not_feature,\n",
    "    len_dataset=len_dataset,\n",
    "    percentage_feature=percentage_feature,\n",
    "    percentage_response_if_feature=percentage_response_if_feature,\n",
    "    percentage_response_if_not_feature=percentage_response_if_not_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sexist_dataset.loc[: , dataset.columns != 'target']\n",
    "Y = sexist_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d78af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb9644",
   "metadata": {},
   "source": [
    "### Bring your own model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a8be6",
   "metadata": {},
   "source": [
    "If you want to bring your own model, you have to set 3 features:\n",
    "\n",
    "1. uncorrected_model_path\n",
    "Save your model in uncorrected_model_path, for fairness analysis on relevant features\n",
    "Ex: uncorrected_model_path = \"/work/data/models/uncorrected_model.pkl\"\n",
    "\n",
    "2. X_train_valid, Y_train_valid\n",
    "pd.DataFrame with your inputs and targets on train&valid set, of shape(nb_individuals,)\n",
    "\n",
    "3. Y_pred_train_valid\n",
    "np.ndarray with the predicted label (i.e. class) or value, of shape(nb_individuals,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63447f8c",
   "metadata": {},
   "source": [
    "### Automatically train a model statistically performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e01c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_train_valid, X_test, Y_train, Y_valid, Y_train_valid, Y_test = train_valid_test_split(\n",
    "    X=X,\n",
    "    Y=Y, \n",
    "    model_task=model_task,\n",
    "    preprocessing_cat_features=preprocessing_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99abfa",
   "metadata": {},
   "source": [
    "# Represent data - from tables to graph (on X_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756db59",
   "metadata": {},
   "source": [
    "From this dataset (where we introduced selectively a \"sexist\" effect against women), let's see how we could swith from the tabular data to a graph representation.\n",
    "\n",
    "The point is that our features X all seem to be attributes of the clients, though we should find a way of representing their interactions between clients \n",
    "\n",
    "X = {race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, occupation, hours per week, workclass, race, sex, capital gain, capital loss, native country} \n",
    "\n",
    "**Nodes** \n",
    "Bank clients (by ID)\n",
    "\n",
    "**Edges** \n",
    "Here, we should find one or several ways of connecting the clients\n",
    "\n",
    "Should be occupation → if changes of occupation (or similar client with new occupation), which impact on the revenue? // change of football team => impact on the football rate \n",
    "(pers) actionable => predict revenue when switches to a new job??\n",
    "→ may be: “hours per week” <=> inspect the change of revenue if switches to greater hours per week?\n",
    "\n",
    "**Node Features** \n",
    "Attributs of the nodes, i.e. characteristics of the clients (here, hard to separate from what \"connects\" them...) \n",
    "\n",
    "Race, age, sex, final weight (depends on age, sex, hispanic origin, race), education, education number, marital status, relationship, hours per week, workclass, race, sex, capital gain, capital loss, native country \n",
    "\n",
    "**Label (here at a node-level?)** \n",
    "Income (Y = income > $50 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0102966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all, specify the edge\n",
    "edge = \"occupation\"# str (for the moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f39c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure that we have no duplicate nodes\n",
    "X_train_valid.index.unique().shape[0] == X_train_valid.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630b5b8",
   "metadata": {},
   "source": [
    "**Extract the node features**\n",
    "\n",
    "The node features are typically represented in a matrix of the shape (num_nodes, node_feature_dim).\n",
    "\n",
    "For each of the bank clients, we simply extract their attributes (except here the \"occupation\", that would be used as an \"actionable\" edge to connect them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01803143",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = X_train_valid.loc[:, X_train_valid.columns != edge]\n",
    "node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8741f5",
   "metadata": {},
   "source": [
    "That's already our node feature matrix. The number of nodes and the ordering is implicitly defined by it's shape. Each row corresponds to one node in our final graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08846427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "x = node_features.to_numpy()\n",
    "x.shape # [num_nodes x num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b8972",
   "metadata": {},
   "source": [
    "**Extract the labels**\n",
    "\n",
    "Those are simply the wealthiness of each of the clients (if their income is >$50 000). This corresponds to a node-level prediction problem. Therefore we have as many labels as we have nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8420d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Y_train_valid\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec957f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make the graph functioning, check that the nodes follow the same order than the labels (rows n°)\n",
    "# else, sort values by ids\n",
    "\n",
    "nb_corresponding_nodes_labels = (labels.index == node_features.index).sum()\n",
    "\n",
    "nb_corresponding_nodes_labels == X_train_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "y = labels.to_numpy()\n",
    "y.shape # [num_nodes, 1] --> node regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c6616",
   "metadata": {},
   "source": [
    "**Extract the edges**\n",
    "\n",
    "That's probably the trickiest part with a tabular dataset. You need to think of a reasonable way to connect your nodes. As mentioned previously, we will use the team assignment here.\n",
    "\n",
    "    AGAIN: There are many ways to connect the entities in a dataset and this approach is very trivial (as it will lead to disconnected subgraphs). If I wanted to build a real model from this dataset, I would probably look for a more sophisticated way to connect the clients. Using a GNN is a bit overkill for the way I model the edges.\n",
    "\n",
    "We now need to find the pairs of clients that are assigned to the same type of job. Let's first check how many clients per type of job we have."
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd75772e",
   "metadata": {},
   "source": [
    "X[edge].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f59ba0d9",
   "metadata": {},
   "source": [
    "X.apply(le.fit_transform)[edge].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403774e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an idea of the codes corresponding to occupations, reconstituting labels' transformations from X\n",
    "dict_occupation_codes = pd.Series(X[edge].values, index=X.apply(le.fit_transform)[edge]).to_dict()\n",
    "\n",
    "# correct according to dict comparison\n",
    "dict_occupation_codes[14] = 'Transport-moving'\n",
    "dict_occupation_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the profession types, this tells us how many clients per type of profession we have to connect\n",
    "df_jobs = X_train_valid.replace({\"occupation\": dict_occupation_codes})\n",
    "df_jobs[\"occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ce335",
   "metadata": {},
   "source": [
    "We now need to build all permutations of these clients within one type of job, which corresponds to a fully-connected graph within each occupation-subgroup. We use the column int_player_id as indices for the edges. If there is for example a [0, 1] in the edge index, it means that the first and second node (regarding the previously defined node feature matrix) are connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6104e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = X_train_valid[\"occupation\"].unique()\n",
    "all_edges = np.array([], dtype=np.int32).reshape((0, 2))\n",
    "for job in jobs:\n",
    "    job_df = X_train_valid[X_train_valid[\"occupation\"] == job]\n",
    "    clients = job_df.index\n",
    "    # Build all combinations, as all players are connected\n",
    "    permutations = list(itertools.combinations(clients, 2))\n",
    "    edges_source = [e[0] for e in permutations]\n",
    "    edges_target = [e[1] for e in permutations]\n",
    "    clients_edges = np.column_stack([edges_source, edges_target])\n",
    "    all_edges = np.vstack([all_edges, clients_edges])\n",
    "# Convert to Pytorch Geometric format\n",
    "edge_index = all_edges.transpose()\n",
    "edge_index # [2, num_edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecfd41b",
   "metadata": {},
   "source": [
    "The result are these source/target edge pairs. Here you can also model dircted or undirected edges by inluding both or just one direction (I included both). This COO format is usually chosen as it is more efficient than a NxN adjacency matrix.\n",
    "\n",
    "**To Do then: include ONE-SENSE direction** for certain features (against non-sense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4189d5e",
   "metadata": {},
   "source": [
    "**Final step - build the graph dataset**\n",
    "\n",
    "Now we have all the components we need to build a graph for libraries like Pytorch Geometric or DGL. \n",
    "\n",
    "We need to pass the numpy arrays to the Data object, like this. If you have further attributes like edge_features, you can also pass them here.\n",
    "\n",
    "(pers) work hours and sector --> edge features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438539df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the uncorrected model, to then sort its features by importances\n",
    "save_model=True\n",
    "uncorrected_model_path = \"/work/data/models/uncorrected_model.pkl\"\n",
    "\n",
    "Y_pred_train_valid = train_naive_xgb(\n",
    "    X_train=X_train,\n",
    "    X_valid=X_valid,\n",
    "    X_train_valid=X_train_valid,\n",
    "    X_test=X_test,\n",
    "    Y_train=Y_train,\n",
    "    Y_valid=Y_valid,\n",
    "    Y_train_valid=Y_train_valid,\n",
    "    Y_test=Y_test,\n",
    "    model_task=model_task,\n",
    "    stat_criteria=stat_criteria,\n",
    "    save_model=save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b5cd3",
   "metadata": {},
   "source": [
    "### Basic analysis of the model: DataFrame with the results, Feature Importance from Shapley values (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32837850",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_valid_set = augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e3a0f",
   "metadata": {},
   "source": [
    "We now see that this process with basic data preparation, modelling and integration of the results in a DataFrame (as storage of the model) is very fast (in seconds):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebefe615",
   "metadata": {},
   "source": [
    "features_importances_from_pickle(\n",
    "    augmented_train_valid_set=augmented_train_valid_set,\n",
    "    X_train_valid=X_train_valid,\n",
    "    model_task=model_task,\n",
    "    uncorrected_model_path=uncorrected_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "print(f\"Basic modelling took {round(t1 - t0)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c6a49",
   "metadata": {},
   "source": [
    "The further steps are for fairness assessment and correction of the model, functionality which is available with the package FairDream of DreamQuark (private for the moment)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48be396",
   "metadata": {},
   "source": [
    "## Detection alert (on train&valid data to examine if the model learned discriminant behavior)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4108de8c",
   "metadata": {},
   "source": [
    "augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddfaf680",
   "metadata": {},
   "source": [
    "train_valid_set_with_uncorrected_results = augment_train_valid_set_with_results(\"uncorrected\", X_train_valid, Y_train_valid, Y_pred_train_valid, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1da81ac9",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "augmented_train_valid_set = train_valid_set_with_uncorrected_results\n",
    "model_name = \"uncorrected\"\n",
    "\n",
    "fairness_purpose='percentage_positive'\n",
    "injustice_acceptance=1\n",
    "min_individuals_discrimined=0.01\n",
    "\n",
    "discrimination_alert(augmented_train_valid_set, model_name, fairness_purpose, model_task, injustice_acceptance, min_individuals_discrimined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6fb59",
   "metadata": {},
   "source": [
    "## Discrimination correction with a new fair model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbadc17",
   "metadata": {},
   "source": [
    "### Generating fairer models with grid search or weights distorsion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5e1dad5",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# the user determines one's fairness objectives to build new fairer models\n",
    "# on which group and regarding which criteria (purpose, constraint of the models) one aims to erase discrimination\n",
    "\n",
    "protected_attribute = 'education-num'\n",
    "\n",
    "# then the user sets the desired balance between stat and fair performances \n",
    "tradeoff = \"moderate\"\n",
    "weight_method = 'grid_and_weighted_groups'\n",
    "nb_fair_models = 6\n",
    "\n",
    "\n",
    "train_valid_set_with_corrected_results, models_df, best_model_dict = fair_train(\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    train_valid_set_with_uncorrected_results=train_valid_set_with_uncorrected_results,\n",
    "    protected_attribute=protected_attribute,\n",
    "    fairness_purpose=fairness_purpose,\n",
    "    model_task=model_task,\n",
    "    stat_criteria=stat_criteria,\n",
    "    tradeoff=tradeoff,\n",
    "    weight_method=weight_method,\n",
    "    nb_fair_models=nb_fair_models,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35c752",
   "metadata": {},
   "source": [
    "### Evaluating the best fair model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39cd5d2d",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fair_model_results(train_valid_set_with_corrected_results, models_df, best_model_dict,protected_attribute,fairness_purpose, model_task)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef3cfd4f",
   "metadata": {},
   "source": [
    "top_models = models_df.sort_values(by='tradeoff_score',ascending=False)\n",
    "top_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
